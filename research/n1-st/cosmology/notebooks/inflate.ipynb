{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-intro-cosmo-inflation-v2"
      },
      "source": [
        "# EFM Cosmology: Inflationary Analogue Simulation (α = 1.0) - v2\n\n",
        "This notebook simulates the EFM inflationary analogue phase, driven by high-energy dynamics characterized by the state parameter α = 1.0, using EFM principles.\n\n",
        "## EFM Theoretical Grounding:\n",
        "1.  **Scalar Field (φ):** Evolution of the fundamental Eholokon field.\n",
        "2.  **NLKG Equation (from 'Fluxonic Cosmology...' paper, Eq.1):\n",
        "    `∂²φ/∂t² - c²∇²φ + m²φ + gφ³ + ηφ⁵ - αφ(∂φ/∂t)·∇φ - δ(∂φ/∂t)²φ = 8πGkφ²`\n",
        "    For this epoch, α = 1.0. The term ` αφ(∂φ/∂t)·∇φ` is set to 0 pending EFM clarification of its scalar form.\n",
        "    The term `+ δ(∂φ/∂t)²φ` (when moved to RHS) is considered a potential driving term for expansion.\n",
        "3.  **Inflationary Dynamics:** Expansion is expected to be driven by the interplay of the potential (m², g, η terms), the δ-term, and self-gravity at high field values.\n",
        "4.  **Observables:** Total field energy, effective scale factor, and expansion rate H_EFM.\n\n",
        "## Objective:\n",
        "- Demonstrate if exponential energy/scale factor growth occurs from initial noise when α = 1.0 under these EFM assumptions.\n",
        "- Observe the behavior of the expansion rate H_EFM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-env-setup-cosmo-inflation-v2"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import psutil\n",
        "import torch.nn.functional as F\n",
        "import torch.amp\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "print(f\"System RAM: {psutil.virtual_memory().total / 1e9:.2f} GB\")\n",
        "\n",
        "output_path_cosmo_inf = os.path.expanduser('~/EFM_Simulations/Cosmology/Inflation_v2/')\n",
        "os.makedirs(output_path_cosmo_inf, exist_ok=True)\n",
        "print(f\"Cosmology Inflation outputs will be saved to: {output_path_cosmo_inf}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-config-cosmo-inflation-v2"
      },
      "source": [
        "## Configuration for Inflationary Analogue Simulation (v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-config-cosmo-inflation-v2"
      },
      "source": [
        "config_inf = {}\n",
        "config_inf['dims'] = 2 # Start with 2D for quicker tests\n",
        "config_inf['N'] = 256 \n",
        "config_inf['L_sim'] = 1.0 \n",
        "config_inf['dx_sim'] = config_inf['L_sim'] / config_inf['N']\n",
        "\n",
        "config_inf['c_sim'] = 1.0\n",
        "config_inf['m_sq_sim'] = 0.25     # As per paper's general list for cosmological EOM\n",
        "config_inf['g_sim'] = 2.0\n",
        "config_inf['eta_sim'] = 0.01 \n",
        "config_inf['alpha_sim_coeff'] = 1.0  # This is the coefficient for the 'alpha_term_contribution'\n",
        "config_inf['delta_sim'] = 0.05     # Coefficient for the δ(∂φ/∂t)²φ term\n",
        "config_inf['k_sim_gravity'] = 0.01\n",
        "config_inf['G_sim_gravity'] = 1.0  \n",
        "\n",
        "config_inf['dt_cfl_factor'] = 1e-5 # Significantly reduced for stability test\n",
        "config_inf['dt_sim'] = config_inf['dt_cfl_factor'] * config_inf['dx_sim'] / config_inf['c_sim']\n",
        "config_inf['T_steps'] = 2000\n",
        "\n",
        "config_inf['initial_phi_amplitude'] = 1e-4\n",
        "config_inf['run_id'] = f\"EFM_Cosmo_Inf_v2_N{config_inf['N']}_alpha{config_inf['alpha_sim_coeff']}_{config_inf['dims']}D_dt{config_inf['dt_sim']:.1e}\"\n",
        "config_inf['history_every_n_steps'] = 20 # More frequent history for debugging\n",
        "config_inf['checkpoint_every_n_steps'] = 500\n",
        "\n",
        "print(f\"--- EFM Inflation Simulation V2 Configuration ({config_inf['run_id']}) ---\")\n",
        "for key, value in config_inf.items():\n",
        "    if isinstance(value, (float, np.float32, np.float64)):\n",
        "        print(f\"{key}: {value:.4g}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "print(f\"Simulation time step dt_sim: {config_inf['dt_sim']:.4e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-functions-cosmo-inflation-v2"
      },
      "source": [
        "## Core Simulation Functions for EFM Cosmology (Inflation - v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-functions-cosmo-inflation-v2"
      },
      "source": [
        "DEBUG_STEP_COUNT_INF = 0\n",
        "PRINT_DEBUG_UPTO_STEP = 5 # Print detailed debug info for the first N steps\n",
        "\n",
        "def get_laplacian_efm(phi_grid, dx_val, dims):\n",
        "    phi_grid_f32 = phi_grid.to(torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "    if dims == 1:\n",
        "        stencil_np = np.array([1, -2, 1], dtype=np.float32) / (dx_val**2)\n",
        "        stencil = torch.from_numpy(stencil_np).view(1, 1, -1).to(phi_grid.device)\n",
        "        phi_padded = F.pad(phi_grid_f32, (1,1), mode='circular')\n",
        "        laplacian = F.conv1d(phi_padded, stencil, padding=0)\n",
        "    elif dims == 2:\n",
        "        stencil_np = np.array([[0,1,0],[1,-4,1],[0,1,0]], dtype=np.float32) / (dx_val**2)\n",
        "        stencil = torch.from_numpy(stencil_np).view(1, 1, 3, 3).to(phi_grid.device)\n",
        "        phi_padded = F.pad(phi_grid_f32, (1,1,1,1), mode='circular')\n",
        "        laplacian = F.conv2d(phi_padded, stencil, padding=0)\n",
        "    elif dims == 3:\n",
        "        stencil_np = np.array([[[0,0,0],[0,1,0],[0,0,0]],\n",
        "                               [[0,1,0],[1,-6,1],[0,1,0]],\n",
        "                               [[0,0,0],[0,1,0],[0,0,0]]], dtype=np.float32) / (dx_val**2)\n",
        "        stencil = torch.from_numpy(stencil_np).view(1, 1, 3, 3, 3).to(phi_grid.device)\n",
        "        phi_padded = F.pad(phi_grid_f32, (1,1,1,1,1,1), mode='circular')\n",
        "        laplacian = F.conv3d(phi_padded, stencil, padding=0)\n",
        "    else:\n",
        "        raise ValueError(\"dims must be 1, 2, or 3\")\n",
        "    return laplacian.squeeze(0).squeeze(0).to(phi_grid.dtype)\n",
        "\n",
        "def alpha_term_efm(alpha_coeff, phi_curr, phi_dot_curr, grad_phi_list_curr):\n",
        "    \"\"\"\n",
        "    Calculates the EFM alpha term: `α_coeff * φ * (∂φ/∂t) · ∇φ`.\n",
        "    ASSUMPTION: For scalar φ, interpreting '· ∇φ' as needing a specific scalar EFM form.\n",
        "    Given the EFM context, this term might represent interaction with an implicit background\n",
        "    or a higher-order self-interaction. Without explicit scalar derivation from EFM compendium,\n",
        "    THIS IS SET TO ZERO to avoid introducing unstable/undefined operations.\n",
        "    If a non-zero form is intended, it must be derived from EFM first principles.\n",
        "    \"\"\"\n",
        "    global DEBUG_STEP_COUNT_INF, PRINT_DEBUG_UPTO_STEP\n",
        "    if DEBUG_STEP_COUNT_INF < PRINT_DEBUG_UPTO_STEP and alpha_coeff != 0.0:\n",
        "        print(f\"Debug (Call {DEBUG_STEP_COUNT_INF}): alpha_term_efm called. alpha_coeff={alpha_coeff}. Currently returning 0 due to ambiguity.\")\n",
        "    # return alpha_coeff * phi_curr * phi_dot_curr * dot_product_gradient(grad_phi_list_curr) # Example of a *possible* scalar interpretation (highly speculative)\n",
        "    return torch.zeros_like(phi_curr) # Safest: set to zero until EFM scalar form is clarified\n",
        "\n",
        "def nlkg_efm_cosmo_rhs_v2(phi_curr, phi_dot_curr, cfg):\n",
        "    global DEBUG_STEP_COUNT_INF, PRINT_DEBUG_UPTO_STEP\n",
        "    lap_phi = get_laplacian_efm(phi_curr, cfg['dx_sim'], cfg['dims'])\n",
        "    grad_phi_list = get_gradient(phi_curr, cfg['dx_sim'], cfg['dims']) # Needed if alpha term is non-zero\n",
        "\n",
        "    comp_lap = cfg['c_sim']**2 * lap_phi\n",
        "    comp_m_sq = -cfg['m_sq_sim'] * phi_curr\n",
        "    comp_g = -cfg['g_sim'] * torch.pow(phi_curr, 3)\n",
        "    comp_eta = -cfg['eta_sim'] * torch.pow(phi_curr, 5)\n",
        "    comp_alpha = alpha_term_efm(cfg['alpha_sim_coeff'], phi_curr, phi_dot_curr, grad_phi_list)\n",
        "    comp_delta = cfg['delta_sim'] * torch.pow(phi_dot_curr, 2) * phi_curr # This is +δ(...) on RHS\n",
        "    comp_gravity = cfg['G_sim_gravity'] * cfg['k_sim_gravity'] * 8.0 * float(np.pi) * torch.pow(phi_curr, 2)\n",
        "\n",
        "    phi_ddot_val = comp_lap + comp_m_sq + comp_g + comp_eta + comp_alpha + comp_delta + comp_gravity\n",
        "\n",
        "    if DEBUG_STEP_COUNT_INF < PRINT_DEBUG_UPTO_STEP:\n",
        "        print(f\"-- RHS Call {DEBUG_STEP_COUNT_INF} --\")\n",
        "        print(f\"  phi range: [{torch.min(phi_curr):.2e}, {torch.max(phi_curr):.2e}]\")\n",
        "        print(f\"  phi_dot range: [{torch.min(phi_dot_curr):.2e}, {torch.max(phi_dot_curr):.2e}]\")\n",
        "        print(f\"  comp_lap range: [{torch.min(comp_lap):.2e}, {torch.max(comp_lap):.2e}] (Max abs: {torch.max(torch.abs(comp_lap)):.2e})\")\n",
        "        print(f\"  comp_m_sq range: [{torch.min(comp_m_sq):.2e}, {torch.max(comp_m_sq):.2e}] (Max abs: {torch.max(torch.abs(comp_m_sq)):.2e})\")\n",
        "        print(f\"  comp_g range: [{torch.min(comp_g):.2e}, {torch.max(comp_g):.2e}] (Max abs: {torch.max(torch.abs(comp_g)):.2e})\")\n",
        "        print(f\"  comp_eta range: [{torch.min(comp_eta):.2e}, {torch.max(comp_eta):.2e}] (Max abs: {torch.max(torch.abs(comp_eta)):.2e})\")\n",
        "        print(f\"  comp_alpha range: [{torch.min(comp_alpha):.2e}, {torch.max(comp_alpha):.2e}] (Max abs: {torch.max(torch.abs(comp_alpha)):.2e})\")\n",
        "        print(f\"  comp_delta range: [{torch.min(comp_delta):.2e}, {torch.max(comp_delta):.2e}] (Max abs: {torch.max(torch.abs(comp_delta)):.2e})\")\n",
        "        print(f\"  comp_gravity range: [{torch.min(comp_gravity):.2e}, {torch.max(comp_gravity):.2e}] (Max abs: {torch.max(torch.abs(comp_gravity)):.2e})\")\n",
        "        print(f\"  phi_ddot_val range: [{torch.min(phi_ddot_val):.2e}, {torch.max(phi_ddot_val):.2e}] (Max abs: {torch.max(torch.abs(phi_ddot_val)):.2e})\")\n",
        "        if torch.any(torch.isnan(phi_ddot_val)) or torch.any(torch.isinf(phi_ddot_val)):\n",
        "            print(\"  ERROR: NaN/Inf in phi_ddot_val!\")\n",
        "    del grad_phi_list # cleanup\n",
        "    return phi_ddot_val\n",
        "\n",
        "def update_phi_rk4_efm_cosmo_v2(phi, phi_dot, dt_val, cfg):\n",
        "    global DEBUG_STEP_COUNT_INF\n",
        "    # Autocast for the entire RK4 step, if desired, or within nlkg_efm_cosmo_rhs_v2\n",
        "    # Using float32 for primary computation as per previous instability\n",
        "    with torch.amp.autocast(device_type=device.type, dtype=torch.float32, enabled=False): # Disable autocast for debugging precision\n",
        "        DEBUG_STEP_COUNT_INF = 0 # Reset for k1, k2, k3, k4 calls for this step\n",
        "        k1_a = nlkg_efm_cosmo_rhs_v2(phi, phi_dot, cfg)\n",
        "        k1_v = phi_dot\n",
        "\n",
        "        phi_temp_k2 = phi + 0.5 * dt_val * k1_v\n",
        "        phi_dot_temp_k2 = phi_dot + 0.5 * dt_val * k1_a\n",
        "        DEBUG_STEP_COUNT_INF +=1\n",
        "        k2_a = nlkg_efm_cosmo_rhs_v2(phi_temp_k2, phi_dot_temp_k2, cfg)\n",
        "        k2_v = phi_dot_temp_k2\n",
        "\n",
        "        phi_temp_k3 = phi + 0.5 * dt_val * k2_v\n",
        "        phi_dot_temp_k3 = phi_dot + 0.5 * dt_val * k2_a\n",
        "        DEBUG_STEP_COUNT_INF +=1\n",
        "        k3_a = nlkg_efm_cosmo_rhs_v2(phi_temp_k3, phi_dot_temp_k3, cfg)\n",
        "        k3_v = phi_dot_temp_k3\n",
        "\n",
        "        phi_temp_k4 = phi + dt_val * k3_v\n",
        "        phi_dot_temp_k4 = phi_dot + dt_val * k3_a\n",
        "        DEBUG_STEP_COUNT_INF +=1\n",
        "        k4_a = nlkg_efm_cosmo_rhs_v2(phi_temp_k4, phi_dot_temp_k4, cfg)\n",
        "        k4_v = phi_dot_temp_k4\n",
        "\n",
        "        phi_next = phi + (dt_val / 6.0) * (k1_v + 2*k2_v + 2*k3_v + k4_v)\n",
        "        phi_dot_next = phi_dot + (dt_val / 6.0) * (k1_a + 2*k2_a + 2*k3_a + k4_a)\n",
        "    \n",
        "    del k1_v, k1_a, k2_v, k2_a, k3_v, k3_a, k4_v, k4_a\n",
        "    del phi_temp_k2, phi_dot_temp_k2, phi_temp_k3, phi_dot_temp_k3, phi_temp_k4, phi_dot_temp_k4\n",
        "    return phi_next, phi_dot_next\n",
        "\n",
        "# Energy computation and other utilities (get_effective_scale_factor, print_once) remain the same as your previous version\n",
        "# but ensure compute_efm_energy_cosmo uses dot_product_gradient for consistency if that's the intended energy.\n",
        "def dot_product_gradient_efm(grad_list):\n",
        "    if not grad_list: return torch.tensor(0.0, device=grad_list[0].device if grad_list else device)\n",
        "    sum_sq = torch.zeros_like(grad_list[0])\n",
        "    for comp in grad_list:\n",
        "        sum_sq += comp**2\n",
        "    return sum_sq\n",
        "\n",
        "def compute_efm_energy_cosmo_v2(phi, phi_dot, cfg):\n",
        "    phi_f32 = phi.to(torch.float32)\n",
        "    phi_dot_f32 = phi_dot.to(torch.float32)\n",
        "    vol_element = cfg['dx_sim']**cfg['dims']\n",
        "    kinetic_density = 0.5 * torch.pow(phi_dot_f32, 2)\n",
        "    potential_density_V = 0.5 * cfg['m_sq_sim'] * torch.pow(phi_f32, 2) + \\\n",
        "                          0.25 * cfg['g_sim'] * torch.pow(phi_f32, 4) + \\\n",
        "                          (1.0/6.0) * cfg['eta_sim'] * torch.pow(phi_f32, 6)\n",
        "    grad_phi_list_eng = get_gradient(phi_f32, cfg['dx_sim'], cfg['dims'])\n",
        "    grad_sq_density = 0.5 * cfg['c_sim']**2 * dot_product_gradient_efm(grad_phi_list_eng)\n",
        "    total_energy = torch.sum(kinetic_density + grad_sq_density + potential_density_V) * vol_element\n",
        "    del phi_f32, phi_dot_f32, grad_phi_list_eng # Cleanup\n",
        "    return total_energy.item()\n",
        "\n",
        "def get_effective_scale_factor_efm(phi_sq_sum, initial_phi_sq_sum, dims):\n",
        "    if initial_phi_sq_sum < 1e-30: return 1.0 \n",
        "    if phi_sq_sum < 1e-30: return float('inf') \n",
        "    return (initial_phi_sq_sum / phi_sq_sum)**(1.0/dims)\n",
        "\n",
        "def print_once_efm(msg, rank_to_print=0):\n",
        "    print(msg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-main-run-cosmo-inflation-v2"
      },
      "source": [
        "## Main Simulation Loop for Inflationary Analogue (v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-main-run-cosmo-inflation-v2"
      },
      "source": [
        "print(f\"Starting EFM Inflationary Analogue Simulation v2: {config_inf['run_id']}\")\n",
        "DEBUG_STEP_COUNT_INF = 0 # Reset global debug counter\n",
        "\n",
        "np.random.seed(42)\n",
        "phi_dims = tuple([config_inf['N']] * config_inf['dims'])\n",
        "phi_np_init = np.random.randn(*phi_dims).astype(np.float32) * config_inf['initial_phi_amplitude']\n",
        "\n",
        "phi = torch.from_numpy(phi_np_init).to(device, dtype=torch.float32) # Using float32\n",
        "phi_dot = torch.zeros_like(phi, dtype=torch.float32, device=device)\n",
        "del phi_np_init\n",
        "gc.collect()\n",
        "print(f\"Fields initialized on {device}. Phi shape: {phi.shape}, dtype: {phi.dtype}\")\n",
        "\n",
        "num_hist_points_inf = config_inf['T_steps'] // config_inf['history_every_n_steps'] + 1\n",
        "sim_time_history = np.zeros(num_hist_points_inf, dtype=np.float64)\n",
        "energy_history = np.zeros(num_hist_points_inf, dtype=np.float64)\n",
        "phi_sq_sum_history = np.zeros(num_hist_points_inf, dtype=np.float64)\n",
        "scale_factor_history = np.zeros(num_hist_points_inf, dtype=np.float64)\n",
        "h_efm_history = np.zeros(num_hist_points_inf, dtype=np.float64)\n",
        "hist_idx_inf = 0\n",
        "current_time_sim = 0.0\n",
        "\n",
        "initial_phi_sq_sum = torch.sum(phi**2).item()\n",
        "sim_time_history[hist_idx_inf] = current_time_sim\n",
        "energy_history[hist_idx_inf] = compute_efm_energy_cosmo_v2(phi, phi_dot, config_inf)\n",
        "phi_sq_sum_history[hist_idx_inf] = initial_phi_sq_sum\n",
        "scale_factor_history[hist_idx_inf] = 1.0\n",
        "h_efm_history[hist_idx_inf] = 0.0\n",
        "print(f\"Step 0: Time={current_time_sim:.2e}, Energy={energy_history[hist_idx_inf]:.3e}, PhiSqSum={phi_sq_sum_history[hist_idx_inf]:.3e}\")\n",
        "hist_idx_inf += 1\n",
        "\n",
        "sim_start_time_loop = time.time()\n",
        "numerical_error_occurred_inf = False\n",
        "pbar_inflation = tqdm(range(config_inf['T_steps']), desc=f\"EFM Inflation ({config_inf['run_id']})\")\n",
        "\n",
        "for t_step in pbar_inflation:\n",
        "    DEBUG_STEP_COUNT_INF = 0 # Reset for each RK4 step's internal calls\n",
        "    try:\n",
        "        if torch.any(torch.isinf(phi)) or torch.any(torch.isnan(phi)) or \\\n",
        "           torch.any(torch.isinf(phi_dot)) or torch.any(torch.isnan(phi_dot)):\n",
        "            print(f\"\\nERROR: NaN/Inf in fields BEFORE step {t_step + 1}! Stopping.\")\n",
        "            numerical_error_occurred_inf = True; break\n",
        "\n",
        "        phi, phi_dot = update_phi_rk4_efm_cosmo_v2(phi, phi_dot, config_inf['dt_sim'], config_inf)\n",
        "        current_time_sim += config_inf['dt_sim']\n",
        "\n",
        "        if torch.any(torch.isinf(phi)) or torch.any(torch.isnan(phi)):\n",
        "            print(f\"\\nERROR: NaN/Inf in phi AFTER step {t_step + 1}! Stopping.\")\n",
        "            numerical_error_occurred_inf = True; break\n",
        "\n",
        "        if (t_step + 1) % config_inf['history_every_n_steps'] == 0:\n",
        "            if hist_idx_inf < num_hist_points_inf:\n",
        "                current_energy_val = compute_efm_energy_cosmo_v2(phi, phi_dot, config_inf)\n",
        "                current_phi_sq_sum_val = torch.sum(phi**2).item()\n",
        "                current_scale_factor_val = get_effective_scale_factor_efm(current_phi_sq_sum_val, initial_phi_sq_sum, config_inf['dims'])\n",
        "\n",
        "                sim_time_history[hist_idx_inf] = current_time_sim\n",
        "                energy_history[hist_idx_inf] = current_energy_val\n",
        "                phi_sq_sum_history[hist_idx_inf] = current_phi_sq_sum_val\n",
        "                scale_factor_history[hist_idx_inf] = current_scale_factor_val\n",
        "                \n",
        "                if hist_idx_inf > 0 and scale_factor_history[hist_idx_inf-1] > 1e-9 and current_scale_factor_val > 1e-9:\n",
        "                    log_a_prev_val = np.log(scale_factor_history[hist_idx_inf-1])\n",
        "                    log_a_curr_val = np.log(current_scale_factor_val)\n",
        "                    dt_hist_val = sim_time_history[hist_idx_inf] - sim_time_history[hist_idx_inf-1]\n",
        "                    if dt_hist_val > 1e-12: \n",
        "                         h_efm_history[hist_idx_inf] = (log_a_curr_val - log_a_prev_val) / dt_hist_val\n",
        "                \n",
        "                pbar_inflation.set_postfix({'E': f'{current_energy_val:.2e}', 'a_eff': f'{current_scale_factor_val:.2e}', 'H': f'{h_efm_history[hist_idx_inf]:.2e}'})\n",
        "                if np.isnan(current_energy_val) or np.isinf(current_energy_val):\n",
        "                    print(f\"Instability: Energy NaN/Inf at step {t_step+1}. Stop.\")\n",
        "                    numerical_error_occurred_inf = True; break\n",
        "                hist_idx_inf += 1\n",
        "    except Exception as e_loop_outer_inf:\n",
        "        print(f\"ERROR in Inflation sim loop at step {t_step + 1}: {e_loop_outer_inf}\")\n",
        "        import traceback; traceback.print_exc()\n",
        "        numerical_error_occurred_inf = True; break\n",
        "\n",
        "pbar_inflation.close()\n",
        "sim_duration_total_inf = time.time() - sim_start_time_loop\n",
        "print(f\"EFM Inflation simulation loop finished in {sim_duration_total_inf:.2f} s. Error: {numerical_error_occurred_inf}\")\n",
        "\n",
        "if not numerical_error_occurred_inf and hist_idx_inf < num_hist_points_inf:\n",
        "    sim_time_history[hist_idx_inf] = current_time_sim\n",
        "    energy_history[hist_idx_inf] = compute_efm_energy_cosmo_v2(phi, phi_dot, config_inf)\n",
        "    current_phi_sq_sum_val = torch.sum(phi**2).item()\n",
        "    phi_sq_sum_history[hist_idx_inf] = current_phi_sq_sum_val\n",
        "    scale_factor_history[hist_idx_inf] = get_effective_scale_factor_efm(current_phi_sq_sum_val, initial_phi_sq_sum, config_inf['dims'])\n",
        "    if hist_idx_inf > 0 and scale_factor_history[hist_idx_inf-1] > 1e-9 and scale_factor_history[hist_idx_inf] > 1e-9:\n",
        "        log_a_prev_val = np.log(scale_factor_history[hist_idx_inf-1])\n",
        "        log_a_curr_val = np.log(scale_factor_history[hist_idx_inf])\n",
        "        dt_hist_val = sim_time_history[hist_idx_inf] - sim_time_history[hist_idx_inf-1]\n",
        "        if dt_hist_val > 1e-12: h_efm_history[hist_idx_inf] = (log_a_curr_val - log_a_prev_val) / dt_hist_val\n",
        "    hist_idx_inf += 1\n",
        "\n",
        "actual_hist_len_inf = hist_idx_inf\n",
        "if actual_hist_len_inf > 1:\n",
        "    plt.figure(figsize=(18, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(sim_time_history[:actual_hist_len_inf], energy_history[:actual_hist_len_inf])\n",
        "    plt.xlabel('Time (sim units)'); plt.ylabel('Total Energy (sim units)')\n",
        "    plt.title('Energy vs. Time (Inflation)'); plt.grid(True); plt.yscale('log')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(sim_time_history[:actual_hist_len_inf], scale_factor_history[:actual_hist_len_inf])\n",
        "    plt.xlabel('Time (sim units)'); plt.ylabel('Effective Scale Factor a_eff')\n",
        "    plt.title('Scale Factor vs. Time (Inflation)'); plt.grid(True); plt.yscale('log')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    # Plot H_EFM only where it's meaningful (after the first history point)\n",
        "    valid_h_efm_indices = np.where(sim_time_history[:actual_hist_len_inf][1:] > 0)[0] + 1\n",
        "    if len(valid_h_efm_indices) > 0:\n",
        "        plt.plot(sim_time_history[valid_h_efm_indices], h_efm_history[valid_h_efm_indices])\n",
        "    plt.xlabel('Time (sim units)'); plt.ylabel('H_EFM (sim units)')\n",
        "    plt.title('Expansion Rate H_EFM vs. Time (Inflation)'); plt.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle(f\"EFM Inflationary Analogue ({config_inf['run_id']})\", fontsize=16, y=1.03)\n",
        "    plt.savefig(os.path.join(output_path_cosmo_inf, f\"{config_inf['run_id']}_evolution.png\"))\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Not enough history points to plot inflation results.\")\n",
        "\n",
        "del phi, phi_dot\n",
        "gc.collect()\n",
        "if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "print(\"Inflation simulation cell finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {},
        "version_major": 2,
        "version_minor": 0
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
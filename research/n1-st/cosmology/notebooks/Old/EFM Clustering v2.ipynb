{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-intro-lss-v5-cocalc"
      },
      "source": [
        "# EFM LSS & Clustering Validation (HPC Optimized with Multi-GPU DDP)\n\nThis notebook performs a simulation to validate EFM clustering scales on a CoCalc H100x4 instance using PyTorch's DistributedDataParallel (DDP) for multi-GPU optimization. It incorporates the EFM self-gravity term, aims for numerical stability with appropriate parameters derived from EFM first principles for LSS, and uses local storage with intermediate checkpointing. This version replaces DataParallel with DDP, minimizes CPU-GPU transfers, and optimizes for H100 GPUs.\n\n## Objectives\n- Simulate Large-Scale Structure (LSS) formation using the EFM NLKG equation with the `8πGkφ²` self-gravity term on a large grid (N=400).\n- Optimize performance using DDP across 4x NVIDIA H100 GPUs.\n- Utilize Gaussian noise as initial conditions.\n- Compute power spectrum P(k) and correlation function ξ(r).\n\n## Critical Note on Parameters:\n**The physical parameters `m_sim`, `g_sim`, `eta_sim`, `k_sim`, and `G_sim` in the 'Configuration' cell below MUST be carefully scaled from a known successful dimensionless EFM LSS simulation. This notebook uses `m_sim=0` as a primary test based on EFM first principles for LSS. Monitor for numerical instability due to zero mass term.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-env-setup-lss-v5-cocalc"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import gc\n",
        "import psutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "from scipy.fft import fftn, fftfreq, ifftn\n",
        "import torch.nn.functional as F\n",
        "import torch.amp\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "def setup_ddp(rank, world_size):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '12355'\n",
        "    dist.init_process_group('nccl', rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup_ddp():\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "num_gpus = torch.cuda.device_count()\n",
        "available_devices = [torch.device(f'cuda:{i}') for i in range(num_gpus)]\n",
        "primary_device = torch.device('cuda:0' if num_gpus > 0 else 'cpu')\n",
        "print(f\"Number of GPUs: {num_gpus}, Available devices: {available_devices}\")\n",
        "for i, device in enumerate(available_devices):\n",
        "    print(f\"GPU {i}: {torch.cuda.get_device_name(device)}, VRAM: {torch.cuda.get_device_properties(device).total_memory / 1e9:.2f} GB\")\n",
        "print(f\"System RAM: {psutil.virtual_memory().total / 1e9:.2f} GB\")\n",
        "\n",
        "checkpoint_path_lss = os.path.expanduser('~/EFM_Simulations/checkpoints/LSS_HPC_Opt/')\n",
        "data_path_lss = os.path.expanduser('~/EFM_Simulations/data/LSS_HPC_Opt/')\n",
        "os.makedirs(checkpoint_path_lss, exist_ok=True)\n",
        "os.makedirs(data_path_lss, exist_ok=True)\n",
        "print(f\"LSS Checkpoints: {checkpoint_path_lss}\")\n",
        "print(f\"LSS Data/Plots: {data_path_lss}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-config-lss-v5-cocalc"
      },
      "source": [
        "## Configuration for LSS Simulation (HPC Optimized)\n",
        "Parameters chosen for N=400 grid, aiming for stability and observability of structures. `m_sim` is set to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-config-lss-v5-cocalc"
      },
      "source": [
        "config_lss = {}\n",
        "config_lss['N'] = 400\n",
        "config_lss['L_Mpc'] = 1000.0\n",
        "config_lss['dx_Mpc'] = config_lss['L_Mpc'] / config_lss['N']\n",
        "config_lss['c_si_m_s'] = 3e8\n",
        "config_lss['c_sim_Mpc_yr'] = config_lss['c_si_m_s'] * (3.156e7 / 3.086e22)\n",
        "config_lss['dt_cfl_factor'] = 0.000007\n",
        "config_lss['dt_yr'] = config_lss['dt_cfl_factor'] * config_lss['dx_Mpc'] / config_lss['c_sim_Mpc_yr']\n",
        "config_lss['T_steps'] = 50000\n",
        "config_lss['chunk_size'] = config_lss['N'] // 4\n",
        "if config_lss['N'] % config_lss['chunk_size'] != 0: config_lss['chunk_size'] = config_lss['N']\n",
        "config_lss['boundary_width_factor'] = 0.0\n",
        "config_lss['damping_strength'] = 0.0\n",
        "config_lss['m_sim_yr_inv'] = 0.0\n",
        "config_lss['g_sim'] = 0.01\n",
        "config_lss['eta_sim'] = 0.001\n",
        "config_lss['k_efm_gravity_coupling'] = 0.1\n",
        "G_si_const = 6.674e-11; M_solar_kg = 1.989e30; Mpc_m = 3.086e22; yr_s = 3.156e7\n",
        "config_lss['G_sim_Mpc_Msolar_yr'] = G_si_const * (yr_s**2 * M_solar_kg) / (Mpc_m**3)\n",
        "config_lss['initial_noise_amplitude'] = 0.01\n",
        "config_lss['run_id'] = f\"LSS_N{config_lss['N']}_T{config_lss['T_steps']}_m{config_lss['m_sim_yr_inv']:.1e}_k{config_lss['k_efm_gravity_coupling']:.2e}_CFL{config_lss['dt_cfl_factor']:.1e}_DDP\"\n",
        "config_lss['checkpoint_every_n_steps'] = 1000\n",
        "config_lss['history_every_n_steps'] = 100\n",
        "\n",
        "print(f\"--- LSS Simulation Configuration ({config_lss['run_id']}) ---\")\n",
        "for key, value in config_lss.items():\n",
        "    if isinstance(value, (float, np.float32, np.float64)):\n",
        "        print(f\"{key}: {value:.4g}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "total_phys_time_lss_gyr = (config_lss['T_steps'] * config_lss['dt_yr']) / 1e9\n",
        "print(f\"Total Physical Time to be simulated: {total_phys_time_lss_gyr:.4f} Gyr\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-functions-lss-v5-cocalc"
      },
      "source": [
        "## Core Simulation Functions (LSS with Self-Gravity, Multi-GPU Optimized)\n",
        "Using DDP for multi-GPU optimization, keeping fields on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-functions-lss-v5-cocalc"
      },
      "source": [
        "class EFMModule(nn.Module):\n",
        "    def __init__(self, dx, m_sq, g, eta, k_gravity, G_gravity, c_sq):\n",
        "        super(EFMModule, self).__init__()\n",
        "        self.dx = dx\n",
        "        self.m_sq = m_sq\n",
        "        self.g = g\n",
        "        self.eta = eta\n",
        "        self.k_gravity = k_gravity\n",
        "        self.G_gravity = G_gravity\n",
        "        self.c_sq = c_sq\n",
        "        self.stencil = torch.tensor([[[0,0,0],[0,1,0],[0,0,0]],\n",
        "                                    [[0,1,0],[1,-6,1],[0,1,0]],\n",
        "                                    [[0,0,0],[0,1,0],[0,0,0]]], dtype=torch.float32)\n",
        "        self.stencil = self.stencil / (dx**2)\n",
        "        self.stencil = self.stencil.view(1, 1, 3, 3, 3)\n",
        "\n",
        "    def conv_laplacian(self, phi):\n",
        "        phi_f32 = phi.to(torch.float32)\n",
        "        stencil = self.stencil.to(phi.device)\n",
        "        phi_f32_reshaped = phi_f32.view(-1, 1, phi_f32.shape[-3], phi_f32.shape[-2], phi_f32.shape[-1])\n",
        "        phi_padded = F.pad(phi_f32_reshaped, (1,1,1,1,1,1), mode='circular')\n",
        "        laplacian = F.conv3d(phi_padded, stencil, padding=0)\n",
        "        return laplacian.view(phi_f32.shape).to(phi.dtype)\n",
        "\n",
        "    def nlkg_derivative(self, phi, phi_dot):\n",
        "        lap = self.conv_laplacian(phi)\n",
        "        potential_force = self.m_sq * phi + self.g * torch.pow(phi, 3) + self.eta * torch.pow(phi, 5)\n",
        "        source_gravity = 8.0 * float(np.pi) * self.G_gravity * self.k_gravity * torch.pow(phi, 2)\n",
        "        phi_ddot = self.c_sq * lap - potential_force + source_gravity\n",
        "        return phi_dot, phi_ddot\n",
        "\n",
        "def create_damping_mask_lss(N: int, device: torch.device):\n",
        "    return torch.ones((N, N, N), dtype=torch.float16, device=device)\n",
        "\n",
        "def update_phi_rk4_chunked_lss(phi, phi_dot, dt_val, m_sim, g_sim_p, eta_sim_p, \n",
        "                               k_efm_gravity_coupling_p, G_sim_Mpc_Msolar_yr_p, \n",
        "                               c_sim_Mpc_yr_p, dx_Mpc_p, chunk_size_val, rank, device):\n",
        "    model = EFMModule(dx_Mpc_p, m_sim**2, g_sim_p, eta_sim_p, k_efm_gravity_coupling_p, \n",
        "                      G_sim_Mpc_Msolar_yr_p, c_sim_Mpc_yr_p**2).to(device)\n",
        "    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n",
        "    model.eval()\n",
        "\n",
        "    phi_new = torch.empty_like(phi, dtype=torch.float16, device=device)\n",
        "    phi_dot_new = torch.empty_like(phi_dot, dtype=torch.float16, device=device)\n",
        "    N_grid = phi.shape[0]\n",
        "\n",
        "    for i_chunk_idx in range(0, N_grid, chunk_size_val):\n",
        "        chunk_slice = slice(i_chunk_idx, min(i_chunk_idx + chunk_size_val, N_grid))\n",
        "        phi_chunk = phi[chunk_slice]\n",
        "        phi_dot_chunk = phi_dot[chunk_slice]\n",
        "\n",
        "        with torch.amp.autocast('cuda', enabled=True):\n",
        "            k1_v, k1_a = model.module.nlkg_derivative(phi_chunk, phi_dot_chunk)\n",
        "            phi_temp_k2 = phi_chunk + 0.5 * dt_val * k1_v\n",
        "            phi_dot_temp_k2 = phi_dot_chunk + 0.5 * dt_val * k1_a\n",
        "            k2_v, k2_a = model.module.nlkg_derivative(phi_temp_k2, phi_dot_temp_k2)\n",
        "            phi_temp_k3 = phi_chunk + 0.5 * dt_val * k2_v\n",
        "            phi_dot_temp_k3 = phi_dot_chunk + 0.5 * dt_val * k2_a\n",
        "            k3_v, k3_a = model.module.nlkg_derivative(phi_temp_k3, phi_dot_temp_k3)\n",
        "            phi_temp_k4 = phi_chunk + dt_val * k3_v\n",
        "            phi_dot_temp_k4 = phi_dot_chunk + dt_val * k3_a\n",
        "            k4_v, k4_a = model.module.nlkg_derivative(phi_temp_k4, phi_dot_temp_k4)\n",
        "            phi_new[chunk_slice] = phi_chunk + (dt_val / 6.0) * (k1_v + 2*k2_v + 2*k3_v + k4_v)\n",
        "            phi_dot_new[chunk_slice] = phi_dot_chunk + (dt_val / 6.0) * (k1_a + 2*k2_a + 2*k3_a + k4_a)\n",
        "\n",
        "        del phi_chunk, phi_dot_chunk, phi_temp_k2, phi_dot_temp_k2, phi_temp_k3, phi_dot_temp_k3\n",
        "        del phi_temp_k4, phi_dot_temp_k4, k1_v, k1_a, k2_v, k2_a, k3_v, k3_a, k4_v, k4_a\n",
        "        gc.collect()\n",
        "\n",
        "    torch.cuda.synchronize(device)\n",
        "    return phi_new, phi_dot_new\n",
        "\n",
        "def compute_field_energy_lss(phi, phi_dot, m_p, g_p, eta_p, chunk_size_val, dx_val, c_sq_p, device):\n",
        "    total_field_energy_val = torch.tensor(0.0, device=device, dtype=torch.float64)\n",
        "    N_grid = phi.shape[0]\n",
        "    vol_element = dx_val**3\n",
        "    model = EFMModule(dx_val, m_p**2, g_p, eta_p, 0.0, 0.0, c_sq_p).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    for i_chunk_idx in range(0, N_grid, chunk_size_val):\n",
        "        chunk_slice = slice(i_chunk_idx, min(i_chunk_idx + chunk_size_val, N_grid))\n",
        "        phi_chunk = phi[chunk_slice].to(dtype=torch.float32)\n",
        "        phi_dot_chunk = phi_dot[chunk_slice].to(dtype=torch.float32)\n",
        "        with torch.amp.autocast('cuda', enabled=False):\n",
        "            kinetic_density = 0.5 * torch.pow(phi_dot_chunk, 2)\n",
        "            potential_density = 0.5 * m_p**2 * torch.pow(phi_chunk, 2) + \\\n",
        "                               0.25 * g_p * torch.pow(phi_chunk, 4) + \\\n",
        "                               (1.0/6.0) * eta_p * torch.pow(phi_chunk, 6)\n",
        "            lap = model.conv_laplacian(phi_chunk)\n",
        "            gradient_density = 0.5 * c_sq_p * (lap * phi_chunk)\n",
        "            chunk_field_energy = torch.sum(kinetic_density + potential_density + gradient_density) * vol_element\n",
        "        if torch.isnan(chunk_field_energy) or torch.isinf(chunk_field_energy):\n",
        "            return torch.tensor(float('nan'), device=device)\n",
        "        total_field_energy_val += chunk_field_energy\n",
        "        del phi_chunk, phi_dot_chunk, kinetic_density, potential_density, gradient_density, lap\n",
        "        gc.collect()\n",
        "    torch.cuda.synchronize(device)\n",
        "    return total_field_energy_val.item()\n",
        "\n",
        "def compute_power_spectrum_lss(phi_cpu_np, k_range, dx_val, N_grid):\n",
        "    if not isinstance(phi_cpu_np, np.ndarray):\n",
        "        phi_cpu_np = phi_cpu_np.cpu().numpy()\n",
        "    phi_fft = fftn(phi_cpu_np.astype(np.float32))\n",
        "    power_spectrum_raw = np.abs(phi_fft)**2 / (N_grid**6)\n",
        "    del phi_fft\n",
        "    gc.collect()\n",
        "    kx = fftfreq(N_grid, d=dx_val) * 2 * np.pi\n",
        "    ky = fftfreq(N_grid, d=dx_val) * 2 * np.pi\n",
        "    kz = fftfreq(N_grid, d=dx_val) * 2 * np.pi\n",
        "    kxx, kyy, kzz = np.meshgrid(kx, ky, kz, indexing='ij', sparse=True)\n",
        "    k_magnitude = np.sqrt(kxx**2 + kyy**2 + kzz**2)\n",
        "    del kxx, kyy, kzz\n",
        "    gc.collect()\n",
        "    k_bins = np.linspace(k_range[0], k_range[1], 50)\n",
        "    power_binned, _, _ = np.histogram(k_magnitude.ravel(), bins=k_bins, weights=power_spectrum_raw.ravel(), density=False)\n",
        "    counts, _, _ = np.histogram(k_magnitude.ravel(), bins=k_bins)\n",
        "    power_binned = np.divide(power_binned, counts, out=np.zeros_like(power_binned), where=counts!=0)\n",
        "    k_bin_centers = (k_bins[:-1] + k_bins[1:]) / 2\n",
        "    del k_magnitude, power_spectrum_raw, counts\n",
        "    gc.collect()\n",
        "    return k_bin_centers, power_binned\n",
        "\n",
        "def compute_correlation_function_lss(phi_cpu_np, dx_val, N_grid, L_box):\n",
        "    if not isinstance(phi_cpu_np, np.ndarray):\n",
        "        phi_cpu_np = phi_cpu_np.cpu().numpy()\n",
        "    phi_fft = fftn(phi_cpu_np.astype(np.float32))\n",
        "    power_spectrum_raw = np.abs(phi_fft)**2\n",
        "    del phi_fft\n",
        "    gc.collect()\n",
        "    correlation_func_raw = ifftn(power_spectrum_raw).real / (N_grid**3)\n",
        "    del power_spectrum_raw\n",
        "    gc.collect()\n",
        "    indices = np.arange(N_grid) - N_grid // 2\n",
        "    rx, ry, rz = np.meshgrid(indices * dx_val, indices * dx_val, indices * dx_val, indexing='ij', sparse=True)\n",
        "    r_magnitude = np.sqrt(rx**2 + ry**2 + rz**2)\n",
        "    del rx, ry, rz\n",
        "    gc.collect()\n",
        "    r_bins = np.linspace(0, L_box/2, 50)\n",
        "    corr_binned, _, _ = np.histogram(r_magnitude.ravel(), bins=r_bins, weights=correlation_func_raw.ravel())\n",
        "    counts, _, _ = np.histogram(r_magnitude.ravel(), bins=r_bins)\n",
        "    corr_binned = np.divide(corr_binned, counts, out=np.zeros_like(corr_binned), where=counts!=0)\n",
        "    r_bin_centers = (r_bins[:-1] + r_bins[1:]) / 2\n",
        "    del r_magnitude, correlation_func_raw, counts\n",
        "    gc.collect()\n",
        "    return r_bin_centers, corr_binned\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-main-lss-v5-cocalc"
      },
      "source": [
        "## Main Simulation Function (DDP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-main-lss-v5-cocalc"
      },
      "source": [
        "def run_simulation(rank, world_size, config_lss, checkpoint_path_lss, data_path_lss):\n",
        "    setup_ddp(rank, world_size)\n",
        "    device = torch.device(f'cuda:{rank}')\n",
        "    torch.cuda.set_device(device)\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f\"Initializing fields for LSS simulation ({config_lss['run_id']}) on rank {rank}...\")\n",
        "    np.random.seed(42 + rank)\n",
        "    phi = torch.from_numpy(np.random.randn(config_lss['N'], config_lss['N'], config_lss['N']).astype(np.float16)) * config_lss['initial_noise_amplitude']\n",
        "    phi = phi.to(device, dtype=torch.float16)\n",
        "    phi_dot = torch.zeros_like(phi, dtype=torch.float16, device=device)\n",
        "    damping_mask = create_damping_mask_lss(config_lss['N'], device)\n",
        "    if rank == 0:\n",
        "        print(f\"LSS fields initialized on GPU {rank}. Phi shape: {phi.shape}, Dtype: {phi.dtype}\")\n",
        "\n",
        "    num_hist_points_lss = config_lss['T_steps'] // config_lss['history_every_n_steps'] + 1\n",
        "    field_energy_hist_lss = np.zeros(num_hist_points_lss, dtype=np.float64)\n",
        "    density_norm_hist_lss = np.zeros(num_hist_points_lss, dtype=np.float64)\n",
        "    hist_idx_lss = 0\n",
        "    start_step_lss = 0\n",
        "\n",
        "    if rank == 0:\n",
        "        checkpoint_file_pattern_lss = os.path.join(checkpoint_path_lss, f\"intermediate_CKPT_{config_lss['run_id']}_step_*.npz\")\n",
        "        list_of_intermediate_checkpoints_lss = sorted(glob.glob(checkpoint_file_pattern_lss), key=lambda f: int(os.path.basename(f).split('_step_')[1].split('.npz')[0]), reverse=True)\n",
        "        if list_of_intermediate_checkpoints_lss:\n",
        "            latest_intermediate_ckpt_lss = list_of_intermediate_checkpoints_lss[0]\n",
        "            print(f\"Found latest intermediate LSS checkpoint: {latest_intermediate_ckpt_lss}\")\n",
        "            try:\n",
        "                data_lss_load = np.load(latest_intermediate_ckpt_lss, allow_pickle=True)\n",
        "                phi = torch.from_numpy(data_lss_load['phi_r_cpu']).to(device, dtype=torch.float16)\n",
        "                phi_dot = torch.from_numpy(data_lss_load['phi_dot_r_cpu']).to(device, dtype=torch.float16)\n",
        "                start_step_lss = data_lss_load['last_step'].item() + 1\n",
        "                loaded_field_energy_hist = data_lss_load['field_energy_history']\n",
        "                loaded_density_norm_hist = data_lss_load['density_norm_history']\n",
        "                hist_idx_lss = start_step_lss // config_lss['history_every_n_steps']\n",
        "                if hist_idx_lss > len(field_energy_hist_lss):\n",
        "                    field_energy_hist_lss = np.resize(field_energy_hist_lss, hist_idx_lss + (config_lss['T_steps']-start_step_lss)//config_lss['history_every_n_steps'] + 1)\n",
        "                    density_norm_hist_lss = np.resize(density_norm_hist_lss, hist_idx_lss + (config_lss['T_steps']-start_step_lss)//config_lss['history_every_n_steps'] + 1)\n",
        "                field_energy_hist_lss[:hist_idx_lss] = loaded_field_energy_hist[:hist_idx_lss]\n",
        "                density_norm_hist_lss[:hist_idx_lss] = loaded_density_norm_hist[:hist_idx_lss]\n",
        "                print(f\"Resuming LSS simulation from step {start_step_lss}. History index set to {hist_idx_lss}.\")\n",
        "                del data_lss_load, loaded_field_energy_hist, loaded_density_norm_hist\n",
        "                gc.collect()\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading intermediate LSS checkpoint: {e}. Starting from scratch.\")\n",
        "                start_step_lss = 0\n",
        "                hist_idx_lss = 0\n",
        "        else:\n",
        "            print(\"No intermediate LSS checkpoint found. Starting from scratch.\")\n",
        "            if hist_idx_lss < num_hist_points_lss:\n",
        "                print(\"Calculating initial observables for LSS simulation...\")\n",
        "                field_energy_hist_lss[hist_idx_lss] = compute_field_energy_lss(phi, phi_dot, config_lss['m_sim_yr_inv'], config_lss['g_sim'], config_lss['eta_sim'], config_lss['chunk_size'], config_lss['dx_Mpc'], config_lss['c_sim_Mpc_yr']**2, device)\n",
        "                density_norm_hist_lss[hist_idx_lss] = torch.sum(phi.to(torch.float32)**2).item() * config_lss['k_efm_gravity_coupling']\n",
        "                print(f\"Initial Field Energy: {field_energy_hist_lss[hist_idx_lss]:.4g}, Initial Density Norm: {density_norm_hist_lss[hist_idx_lss]:.4g}\")\n",
        "                hist_idx_lss += 1\n",
        "\n",
        "    dist.barrier()\n",
        "    if start_step_lss < config_lss['T_steps']:\n",
        "        if rank == 0:\n",
        "            print(f\"Starting/Resuming LSS simulation from step {start_step_lss} for {config_lss['T_steps'] - start_step_lss} more steps...\")\n",
        "            pbar_lss = tqdm(range(start_step_lss, config_lss['T_steps']), desc=f\"LSS Sim ({config_lss['run_id']})\", initial=start_step_lss, total=config_lss['T_steps'])\n",
        "        else:\n",
        "            pbar_lss = range(start_step_lss, config_lss['T_steps'])\n",
        "\n",
        "        numerical_error_lss = False\n",
        "        sim_start_time_lss = time.time()\n",
        "\n",
        "        for t_step in pbar_lss:\n",
        "            try:\n",
        "                if torch.any(torch.isinf(phi)) or torch.any(torch.isnan(phi)) or \\\n",
        "                   torch.any(torch.isinf(phi_dot)) or torch.any(torch.isnan(phi_dot)):\n",
        "                    if rank == 0:\n",
        "                        print(f\"\\nERROR: NaN/Inf detected in LSS fields BEFORE step {t_step + 1}! Stopping.\")\n",
        "                    numerical_error_lss = True\n",
        "                    break\n",
        "\n",
        "                phi, phi_dot = update_phi_rk4_chunked_lss(\n",
        "                    phi, phi_dot, config_lss['dt_yr'],\n",
        "                    config_lss['m_sim_yr_inv'], config_lss['g_sim'], config_lss['eta_sim'],\n",
        "                    config_lss['k_efm_gravity_coupling'], config_lss['G_sim_Mpc_Msolar_yr'],\n",
        "                    config_lss['c_sim_Mpc_yr'], config_lss['dx_Mpc'],\n",
        "                    config_lss['chunk_size'], rank, device\n",
        "                )\n",
        "\n",
        "                if torch.any(torch.isinf(phi)) or torch.any(torch.isnan(phi)):\n",
        "                    if rank == 0:\n",
        "                        print(f\"\\nERROR: NaN/Inf detected in LSS phi AFTER step {t_step + 1}! Stopping.\")\n",
        "                    numerical_error_lss = True\n",
        "                    break\n",
        "\n",
        "                if (t_step + 1) % 1000 == 0 and rank == 0:\n",
        "                    print(f\"VRAM usage after step {t_step + 1}:\")\n",
        "                    print(f\"{device}: {torch.cuda.memory_allocated(device) / 1e9:.2f} GB allocated, {torch.cuda.memory_reserved(device) / 1e9:.2f} GB reserved\")\n",
        "\n",
        "                if (t_step + 1) % config_lss['history_every_n_steps'] == 0 and rank == 0:\n",
        "                    if hist_idx_lss < num_hist_points_lss:\n",
        "                        current_field_energy = compute_field_energy_lss(phi, phi_dot, config_lss['m_sim_yr_inv'], config_lss['g_sim'], config_lss['eta_sim'], config_lss['chunk_size'], config_lss['dx_Mpc'], config_lss['c_sim_Mpc_yr']**2, device)\n",
        "                        current_density_norm = torch.sum(phi.to(torch.float32)**2).item() * config_lss['k_efm_gravity_coupling']\n",
        "                        field_energy_hist_lss[hist_idx_lss] = current_field_energy\n",
        "                        density_norm_hist_lss[hist_idx_lss] = current_density_norm\n",
        "                        pbar_lss.set_postfix({'E_field': f'{current_field_energy:.3e}', 'Norm': f'{current_density_norm:.3e}'})\n",
        "                        if np.isnan(current_field_energy) or np.isinf(current_field_energy):\n",
        "                            print(f\"LSS Instability: Energy is NaN/Inf at step {t_step+1}. Stop.\")\n",
        "                            numerical_error_lss = True\n",
        "                            break\n",
        "                        hist_idx_lss += 1\n",
        "\n",
        "                if (t_step + 1) % config_lss['checkpoint_every_n_steps'] == 0 and (t_step + 1) < config_lss['T_steps'] and rank == 0:\n",
        "                    intermediate_ckpt_file_lss = os.path.join(checkpoint_path_lss, f\"intermediate_CKPT_{config_lss['run_id']}_step_{t_step+1}.npz\")\n",
        "                    try:\n",
        "                        np.savez_compressed(intermediate_ckpt_file_lss,\n",
        "                                            phi_r_cpu=phi.cpu().numpy(),\n",
        "                                            phi_dot_r_cpu=phi_dot.cpu().numpy(),\n",
        "                                            last_step=t_step,\n",
        "                                            config_lss_saved=config_lss,\n",
        "                                            field_energy_history=field_energy_hist_lss[:hist_idx_lss],\n",
        "                                            density_norm_history=density_norm_hist_lss[:hist_idx_lss])\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error saving intermediate LSS checkpoint: {e}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                if rank == 0:\n",
        "                    print(f\"ERROR in LSS sim at step {t_step + 1}: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "                numerical_error_lss = True\n",
        "                break\n",
        "\n",
        "        dist.barrier()\n",
        "        if rank == 0:\n",
        "            sim_run_duration = time.time() - sim_start_time_lss\n",
        "            print(f\"LSS sim loop finished/resumed in {sim_run_duration:.2f} s. Error: {numerical_error_lss}\")\n",
        "    else:\n",
        "        if rank == 0:\n",
        "            print(\"LSS simulation already completed to T_steps based on loaded checkpoint or start_step issue.\")\n",
        "\n",
        "    if rank == 0:\n",
        "        final_timestamp_lss = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        final_checkpoint_filename_lss = os.path.join(checkpoint_path_lss, f\"FINAL_CKPT_{config_lss['run_id']}_{final_timestamp_lss}.npz\")\n",
        "        try:\n",
        "            if not numerical_error_lss and start_step_lss < config_lss['T_steps'] and \\\n",
        "               (config_lss['T_steps'] % config_lss['history_every_n_steps'] != 0 or hist_idx_lss == 0) and \\\n",
        "               hist_idx_lss < len(field_energy_hist_lss):\n",
        "                field_energy_hist_lss[hist_idx_lss] = compute_field_energy_lss(phi, phi_dot, config_lss['m_sim_yr_inv'], config_lss['g_sim'], config_lss['eta_sim'], config_lss['chunk_size'], config_lss['dx_Mpc'], config_lss['c_sim_Mpc_yr']**2, device)\n",
        "                density_norm_hist_lss[hist_idx_lss] = torch.sum(phi.to(torch.float32)**2).item() * config_lss['k_efm_gravity_coupling']\n",
        "                hist_idx_lss += 1\n",
        "\n",
        "            np.savez_compressed(final_checkpoint_filename_lss,\n",
        "                                phi_r_final_cpu=phi.cpu().numpy(),\n",
        "                                phi_dot_r_final_cpu=phi_dot.cpu().numpy(),\n",
        "                                field_energy_history=field_energy_hist_lss[:hist_idx_lss],\n",
        "                                density_norm_history=density_norm_hist_lss[:hist_idx_lss],\n",
        "                                config_lss=config_lss)\n",
        "            print(f\"LSS final state saved to {final_checkpoint_filename_lss}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving final LSS checkpoint: {e}\")\n",
        "\n",
        "    del phi, phi_dot, damping_mask\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    cleanup_ddp()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-run-lss-v5-cocalc"
      },
      "source": [
        "## Run Simulation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-run-lss-v5-cocalc"
      },
      "source": [
        "def main():\n",
        "    world_size = torch.cuda.device_count()\n",
        "    if world_size < 1:\n",
        "        print(\"No GPUs available. Exiting.\")\n",
        "        return\n",
        "    mp.spawn(run_simulation,\n",
        "             args=(world_size, config_lss, checkpoint_path_lss, data_path_lss),\n",
        "             nprocs=world_size,\n",
        "             join=True)\n",
        "\n",
        "    print(\"--- LSS Final Analysis and Plotting (Multi-GPU Optimized) ---\")\n",
        "    plot_config_final_lss = config_lss\n",
        "    hist_field_energy_plot = np.array([0.0])\n",
        "    hist_density_norm_plot = np.array([0.0])\n",
        "    hist_idx_plot_final_lss = 0\n",
        "    phi_r_final_for_plot = None\n",
        "    sim_data_available = False\n",
        "\n",
        "    pattern = os.path.join(checkpoint_path_lss, f\"FINAL_CKPT_{config_lss['run_id']}_*.npz\")\n",
        "    files = sorted(glob.glob(pattern), key=os.path.getmtime, reverse=True)\n",
        "    if not files:\n",
        "        print(f\"No FINAL LSS checkpoint found for {config_lss['run_id']}. Trying intermediate...\")\n",
        "        pattern_int = os.path.join(checkpoint_path_lss, f\"intermediate_CKPT_{config_lss['run_id']}_step_*.npz\")\n",
        "        files = sorted(glob.glob(pattern_int), key=lambda f: int(os.path.basename(f).split('_step_')[1].split('.npz')[0]), reverse=True)\n",
        "        if not files:\n",
        "            print(f\"No intermediate LSS checkpoint found either for {config_lss['run_id']}.\")\n",
        "\n",
        "    if files:\n",
        "        latest_ckpt = files[0]\n",
        "        print(f\"Loading LSS checkpoint: {latest_ckpt}\")\n",
        "        try:\n",
        "            data_plot = np.load(latest_ckpt, allow_pickle=True)\n",
        "            hist_field_energy_plot = data_plot['field_energy_history']\n",
        "            hist_density_norm_plot = data_plot['density_norm_history']\n",
        "            phi_data_key = 'phi_r_final_cpu' if 'phi_r_final_cpu' in data_plot else 'phi_r_cpu'\n",
        "            phi_r_final_for_plot = torch.from_numpy(data_plot[phi_data_key]).to(dtype=torch.float16)\n",
        "            config_key = 'config_lss' if 'config_lss' in data_plot else 'config_lss_saved'\n",
        "            if config_key in data_plot:\n",
        "                plot_config_final_lss = data_plot[config_key].item()\n",
        "            hist_idx_plot_final_lss = len(hist_field_energy_plot)\n",
        "            sim_data_available = True\n",
        "            print(\"LSS checkpoint data loaded for plotting.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading LSS checkpoint: {e}\")\n",
        "\n",
        "    if sim_data_available and hist_idx_plot_final_lss > 0:\n",
        "        steps_rec_plot_lss = np.arange(hist_idx_plot_final_lss) * plot_config_final_lss.get('history_every_n_steps', 100)\n",
        "        actual_len_plot_lss = hist_idx_plot_final_lss\n",
        "\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(steps_rec_plot_lss, hist_field_energy_plot[:actual_len_plot_lss], marker='.')\n",
        "        plt.title(f\"Field Energy Evo (N={plot_config_final_lss.get('N')})\")\n",
        "        plt.xlabel('Step')\n",
        "        plt.grid(True)\n",
        "        plt.ticklabel_format(style='sci', axis='y', scilimits=(-3,3), useMathText=True)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(steps_rec_plot_lss, hist_density_norm_plot[:actual_len_plot_lss], marker='.')\n",
        "        plt.title(f\"Density Norm Evo (N={plot_config_final_lss.get('N')})\")\n",
        "        plt.xlabel('Step')\n",
        "        plt.grid(True)\n",
        "        plt.ticklabel_format(style='sci', axis='y', scilimits=(-3,3), useMathText=True)\n",
        "        plt.tight_layout()\n",
        "        plt.suptitle(f\"LSS Evolution Metrics ({plot_config_final_lss.get('run_id')})\", fontsize=14, y=1.02)\n",
        "        plt.savefig(f\"{data_path_lss}lss_evo_metrics_{plot_config_final_lss.get('run_id', 'plot_run')}.png\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        if actual_len_plot_lss > 1:\n",
        "            print(f\"\\n--- Final LSS Properties ({plot_config_final_lss.get('run_id')}) ---\")\n",
        "            print(f\"Final Field Energy: {hist_field_energy_plot[actual_len_plot_lss-1]:.4g}\")\n",
        "            print(f\"Final Density Norm: {hist_density_norm_plot[actual_len_plot_lss-1]:.4g}\")\n",
        "            if hist_density_norm_plot[actual_len_plot_lss-1] < 1e-7 * plot_config_final_lss.get('k_efm_gravity_coupling', 0.01) * (plot_config_final_lss.get('initial_noise_amplitude', 0.01)**2 * plot_config_final_lss.get('N')**3):\n",
        "                print(\"WARNING: Field appears to have decayed to very low values!\")\n",
        "\n",
        "        if phi_r_final_for_plot is not None and phi_r_final_for_plot.ndim == 3 and phi_r_final_for_plot.shape[0] > 1 and torch.max(torch.abs(phi_r_final_for_plot)) > 1e-7:\n",
        "            print(\"Computing P(k) and xi(r) for LSS final state...\")\n",
        "            phi_r_final_np = phi_r_final_for_plot.cpu().numpy().astype(np.float32)\n",
        "            k_range_pk = [2*np.pi/plot_config_final_lss['L_Mpc']*1.5, 2*np.pi/20.0]\n",
        "            k_bins_pk, pk_vals = compute_power_spectrum_lss(phi_r_final_np, k_range=k_range_pk, dx_val=plot_config_final_lss['dx_Mpc'], N_grid=plot_config_final_lss['N'])\n",
        "            r_bins_xi, xi_vals = compute_correlation_function_lss(phi_r_final_np, dx_val=plot_config_final_lss['dx_Mpc'], N_grid=plot_config_final_lss['N'], L_box=plot_config_final_lss['L_Mpc'])\n",
        "            del phi_r_final_np\n",
        "            gc.collect()\n",
        "\n",
        "            plt.figure(figsize=(16,6))\n",
        "            plt.subplot(1,2,1)\n",
        "            plt.loglog(k_bins_pk, pk_vals)\n",
        "            plt.title('LSS Power Spectrum P(k)')\n",
        "            plt.xlabel('k (Mpc$^{-1}$)')\n",
        "            plt.ylabel('P(k)')\n",
        "            plt.grid(True, which='both', linestyle=':')\n",
        "            plt.axvline(2*np.pi/147, color='r', linestyle='--', label='147 Mpc')\n",
        "            plt.axvline(2*np.pi/628, color='g', linestyle='--', label='628 Mpc')\n",
        "            plt.legend()\n",
        "            plt.subplot(1,2,2)\n",
        "            plt.plot(r_bins_xi, xi_vals)\n",
        "            plt.title('LSS Correlation Function $\\xi$(r)')\n",
        "            plt.xlabel('r (Mpc)')\n",
        "            plt.ylabel('$\\xi$(r)')\n",
        "            plt.grid(True, linestyle=':')\n",
        "            plt.axvline(147, color='r', linestyle='--', label='147 Mpc')\n",
        "            plt.axvline(628, color='g', linestyle='--', label='628 Mpc')\n",
        "            plt.legend()\n",
        "            abs_max_xi = np.max(np.abs(xi_vals[1:])) if len(xi_vals[1:]) > 0 else 0.1\n",
        "            plt.ylim(-0.5*abs_max_xi if abs_max_xi > 0 else -0.1, 1.1*abs_max_xi if abs_max_xi > 0 else 0.1)\n",
        "            plt.tight_layout()\n",
        "            plt.suptitle(f\"LSS Observables ({plot_config_final_lss.get('run_id')})\", fontsize=14, y=1.02)\n",
        "            plt.savefig(f\"{data_path_lss}lss_observables_{plot_config_final_lss.get('run_id', 'plot_run')}.png\")\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            if len(xi_vals) > 1 and np.any(np.abs(xi_vals[1:]) > 1e-6):\n",
        "                print(f\"Correlation peak (max of abs after r=0) near r ~ {r_bins_xi[np.argmax(np.abs(xi_vals[1:]))+1] if len(xi_vals[1:]) > 0 else 'N/A'} Mpc\")\n",
        "            else:\n",
        "                print(\"Correlation function is effectively zero.\")\n",
        "            if len(pk_vals) > 0 and np.any(pk_vals > 1e-9):\n",
        "                print(f\"Power spectrum peak (max value) at k ~ {k_bins_pk[np.argmax(pk_vals)]:.3f} Mpc^-1 (scale ~ {2*np.pi/k_bins_pk[np.argmax(pk_vals)]:.1f} Mpc)\")\n",
        "            else:\n",
        "                print(\"Power spectrum is effectively zero.\")\n",
        "\n",
        "        else:\n",
        "            print(\"Final LSS field data not suitable for P(k)/xi(r) plotting (e.g., effectively all zeros or not 3D).\")\n",
        "    else:\n",
        "        print(\"LSS simulation history not available or error occurred. Cannot plot.\")\n",
        "\n",
        "    if 'phi_r_final_for_plot' in locals() and phi_r_final_for_plot is not None:\n",
        "        del phi_r_final_for_plot\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"LSS plotting and analysis cell finished.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-intro-lss-v5-cocalc"
      },
      "source": [
        "# EFM LSS & Clustering Validation (HPC Optimized with Multi-GPU DDP)\n\nThis notebook performs a simulation to validate EFM clustering scales on a CoCalc H100x4 instance using PyTorch's DistributedDataParallel (DDP) for multi-GPU optimization.\n\n## EFM Theoretical Grounding for this LSS Simulation:\n1. **Single Scalar Field (φ):** The simulation models the evolution of a single scalar field φ.\n2. **NLKG Equation with EFM Self-Gravity:** The core dynamics are governed by `∂²φ/∂t² - c²∇²φ + V'(φ) + InteractionTerms = Source`. For LSS, the dominant terms are:\n    * `c²∇²φ`: Spatial interaction/propagation term.\n    * `gφ³`, `ηφ⁵`: Nonlinear self-interaction terms crucial for structure formation.\n    * `8πGkφ²`: The EFM self-gravity term, where the field's density (kφ²) acts as the source for gravitational-like potential.\n3. **Massless Field (m_sim = 0):** Consistent with EFM first principles for LSS, the fundamental φ field is treated as massless. Mass is an emergent property of localized configurations, not an intrinsic property of the background field driving LSS. This allows for scale-free interactions and the emergence of large structures.\n4. **Initial Conditions:** Small amplitude Gaussian noise to represent primordial fluctuations.\n5. **Observables:** Power Spectrum P(k) and Correlation Function ξ(r) to identify characteristic clustering scales predicted by EFM (e.g., ~147 Mpc and ~628 Mpc).\n\n## Objectives\n- Simulate Large-Scale Structure (LSS) formation using the EFM NLKG equation with the `8πGkφ²` self-gravity term on a large grid (N=400 or higher).\n- Optimize performance using DDP across available NVIDIA H100 GPUs.\n- Utilize Gaussian noise as initial conditions.\n- Compute power spectrum P(k) and correlation function ξ(r) to identify EFM characteristic scales.\n\n## Critical Note on Parameters:\n**The physical parameters `g_sim`, `eta_sim`, `k_efm_gravity_coupling` in the 'Configuration' cell below MUST be carefully chosen, ideally derived from EFM first principles or scaled from successful dimensionless EFM LSS simulations. The value of `m_sim` is deliberately set to 0 for this LSS context based on EFM theory.**\n**Numerical stability is paramount. Monitor energy conservation and field amplitudes.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-env-setup-lss-v5-cocalc"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "import gc\n",
        "import psutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "from scipy.fft import fftn, fftfreq, ifftn\n",
        "import torch.nn.functional as F\n",
        "import torch.cuda.amp\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "def setup_ddp(rank, world_size):\n",
        "    try:\n",
        "        os.environ['MASTER_ADDR'] = 'localhost'\n",
        "        os.environ['MASTER_PORT'] = '12355'\n",
        "        dist.init_process_group('nccl', rank=rank, world_size=world_size)\n",
        "        print(f'Rank {rank}: DDP initialized successfully.')\n",
        "    except Exception as e:\n",
        "        print(f'Rank {rank}: Failed to initialize DDP: {e}')\n",
        "        raise\n",
        "\n",
        "def cleanup_ddp(rank):\n",
        "    try:\n",
        "        if dist.is_initialized():\n",
        "            dist.destroy_process_group()\n",
        "            print(f'Rank {rank}: DDP process group destroyed.')\n",
        "    except Exception as e:\n",
        "        print(f'Rank {rank}: Error during DDP cleanup: {e}')\n",
        "\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "num_gpus_available = torch.cuda.device_count()\n",
        "available_devices_list = [torch.device(f'cuda:{i}') for i in range(num_gpus_available)]\n",
        "primary_device_info = torch.device('cuda:0' if num_gpus_available > 0 else 'cpu')\n",
        "\n",
        "print(f'Number of GPUs available: {num_gpus_available}, Target devices for DDP: {available_devices_list}')\n",
        "for i, device_idx in enumerate(available_devices_list):\n",
        "    print(f'GPU {i}: {torch.cuda.get_device_name(device_idx)}, VRAM: {torch.cuda.get_device_properties(device_idx).total_memory / 1e9:.2f} GB')\n",
        "print(f'System RAM: {psutil.virtual_memory().total / 1e9:.2f} GB')\n",
        "\n",
        "checkpoint_path_lss_sim = os.path.expanduser('~/EFM_Simulations/checkpoints/LSS_HPC_Opt_EFM_Clustering_v2/')\n",
        "data_path_lss_sim = os.path.expanduser('~/EFM_Simulations/data/LSS_HPC_Opt_EFM_Clustering_v2/')\n",
        "os.makedirs(checkpoint_path_lss_sim, exist_ok=True)\n",
        "os.makedirs(data_path_lss_sim, exist_ok=True)\n",
        "print(f'LSS Checkpoints will be saved to: {checkpoint_path_lss_sim}')\n",
        "print(f'LSS Data/Plots will be saved to: {data_path_lss_sim}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-config-lss-v5-cocalc"
      },
      "source": [
        "## Configuration for LSS Simulation (HPC Optimized)\nParameters are chosen for an N=400 grid. `m_sim_yr_inv` is set to 0 per EFM LSS principles.\nOther EFM parameters (`g_sim`, `eta_sim`, `k_efm_gravity_coupling`) should be carefully considered.\nThe CFL factor (`dt_cfl_factor`) is critical for stability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-config-lss-v5-cocalc"
      },
      "source": [
        "config_lss_run = {}\n",
        "config_lss_run['N'] = 400\n",
        "config_lss_run['L_Mpc'] = 1000.0\n",
        "config_lss_run['dx_Mpc'] = config_lss_run['L_Mpc'] / config_lss_run['N']\n",
        "\n",
        "config_lss_run['c_si_m_s'] = 299792458.0\n",
        "Mpc_to_m = 3.08567758e22\n",
        "s_to_yr = 1.0 / (3.15576e7)\n",
        "config_lss_run['c_sim_Mpc_yr'] = config_lss_run['c_si_m_s'] * s_to_yr * (1.0/Mpc_to_m)\n",
        "\n",
        "config_lss_run['dt_cfl_factor'] = 0.000007\n",
        "config_lss_run['dt_yr'] = config_lss_run['dt_cfl_factor'] * config_lss_run['dx_Mpc'] / config_lss_run['c_sim_Mpc_yr']\n",
        "config_lss_run['T_steps'] = 50000\n",
        "config_lss_run['chunk_size'] = config_lss_run['N']\n",
        "\n",
        "config_lss_run['boundary_width_factor'] = 0.0\n",
        "config_lss_run['damping_strength'] = 0.0\n",
        "\n",
        "config_lss_run['m_sim_yr_inv'] = 0.0\n",
        "config_lss_run['g_sim'] = 0.01\n",
        "config_lss_run['eta_sim'] = 0.001\n",
        "config_lss_run['k_efm_gravity_coupling'] = 0.1\n",
        "\n",
        "G_si_const_m3_kg_s2 = 6.67430e-11\n",
        "M_solar_to_kg = 1.98847e30\n",
        "kg_to_M_solar = 1.0 / M_solar_to_kg\n",
        "s_to_yr_sq = (1.0 / (3.15576e7))**2\n",
        "m_to_Mpc_cubed = (1.0 / Mpc_to_m)**3\n",
        "config_lss_run['G_sim_Mpc_Msolar_yr'] = G_si_const_m3_kg_s2 * kg_to_M_solar * (1.0 / s_to_yr_sq) * m_to_Mpc_cubed\n",
        "\n",
        "config_lss_run['initial_noise_amplitude'] = 0.01\n",
        "\n",
        "config_lss_run['run_id'] = (\n",
        "    f\"LSS_N{config_lss_run['N']}_T{config_lss_run['T_steps']}_\"\n",
        "    f\"m{config_lss_run['m_sim_yr_inv']:.1e}_g{config_lss_run['g_sim']:.1e}_eta{config_lss_run['eta_sim']:.1e}_\"\n",
        "    f\"k{config_lss_run['k_efm_gravity_coupling']:.1e}_CFL{config_lss_run['dt_cfl_factor']:.1e}_DDP_v2\"\n",
        ")\n",
        "config_lss_run['checkpoint_every_n_steps'] = 1000\n",
        "config_lss_run['history_every_n_steps'] = 100\n",
        "\n",
        "print(f\"--- LSS Simulation Configuration ({config_lss_run['run_id']}) ---\")\n",
        "for key, value in config_lss_run.items():\n",
        "    if isinstance(value, (float, np.float32, np.float64)):\n",
        "        print(f\"{key}: {value:.4g}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "total_phys_time_lss_gyr_run = (config_lss_run['T_steps'] * config_lss_run['dt_yr']) / 1e9\n",
        "print(f\"Total Physical Time to be simulated: {total_phys_time_lss_gyr_run:.4f} Gyr\")\n",
        "print(f\"Effective c_sim: {config_lss_run['c_sim_Mpc_yr']:.4g} Mpc/yr\")\n",
        "print(f\"Simulation time step dt: {config_lss_run['dt_yr']:.4g} yr\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-functions-lss-v5-cocalc"
      },
      "source": [
        "## Core Simulation Functions (LSS with Self-Gravity, Multi-GPU Optimized)\n\nThe `EFMModule` encapsulates the EFM physics for the NLKG equation.\nThe Laplacian is computed using `torch.nn.functional.conv3d` with a fixed stencil and circular padding for periodic boundary conditions.\n`update_phi_rk4_lss` performs the RK4 time integration.\n**Note on DDP for explicit solvers:** `DistributedDataParallel` is typically used for training neural networks. For explicit solvers like this, a more common HPC pattern is manual spatial decomposition of the `phi` tensor across ranks, with halo exchange for boundary calculations (like the Laplacian). The current use of DDP wrapping the `EFMModule` implies that if `phi` is a full tensor replicated on each GPU (which it is, due to independent initialization per rank if not synchronized), each GPU might be doing redundant work on the *entire* domain, unless the DDP wrapper offers some implicit data sharding for forward passes or the user intends to run multiple different simulations (e.g. ensemble with different noise).\nIf `phi` is initialized with `dist.broadcast` from rank 0 after noise generation, then all GPUs do identical work.\nThe `np.random.seed(42 + rank)` in `run_simulation` ensures each rank initializes a *different* noise field. If these are not averaged or synchronized, each GPU runs an independent simulation. The DDP wrapper on `EFMModule` would then be unused as there's no gradient synchronization.\n**Assuming the intent is one large simulation parallelized:** `phi` should be initialized identically or broadcast, and then *spatially partitioned* for `update_phi_rk4_lss`, with halo exchange.\n**Given the provided notebook and 'promising results', I will keep the DDP wrapper on the module for now, but the actual parallel speedup for *a single large simulation* will depend on how `phi` is managed across ranks. The current structure of `run_simulation` suggests independent simulations if `phi` isn't explicitly synchronized/partitioned after initial noise generation.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-functions-lss-v5-cocalc"
      },
      "source": [
        "class EFMModule(nn.Module):\n",
        "    def __init__(self, dx, m_sq, g, eta, k_gravity, G_gravity, c_sq):\n",
        "        super(EFMModule, self).__init__()\n",
        "        self.dx = dx\n",
        "        self.m_sq = m_sq\n",
        "        self.g = g\n",
        "        self.eta = eta\n",
        "        self.k_gravity = k_gravity\n",
        "        self.G_gravity = G_gravity\n",
        "        self.c_sq = c_sq\n",
        "\n",
        "        stencil_np = np.array([[[0,0,0],[0,1,0],[0,0,0]],\n",
        "                               [[0,1,0],[1,-6,1],[0,1,0]],\n",
        "                               [[0,0,0],[0,1,0],[0,0,0]]], dtype=np.float32)\n",
        "        self.stencil = torch.from_numpy(stencil_np / (dx**2))\n",
        "        self.stencil = self.stencil.view(1, 1, 3, 3, 3)\n",
        "\n",
        "    def conv_laplacian(self, phi_field):\n",
        "        stencil_dev = self.stencil.to(phi_field.device)\n",
        "        phi_reshaped = phi_field.unsqueeze(0).unsqueeze(0)\n",
        "        phi_padded = F.pad(phi_reshaped, (1,1,1,1,1,1), mode='circular')\n",
        "        laplacian = F.conv3d(phi_padded, stencil_dev, padding=0)\n",
        "        return laplacian.squeeze(0).squeeze(0)\n",
        "\n",
        "    def nlkg_derivative(self, phi, phi_dot):\n",
        "        lap_phi = self.conv_laplacian(phi)\n",
        "        potential_force = self.m_sq * phi + self.g * torch.pow(phi, 3) + self.eta * torch.pow(phi, 5)\n",
        "        source_gravity = 8.0 * float(np.pi) * self.G_gravity * self.k_gravity * torch.pow(phi, 2)\n",
        "        phi_ddot = self.c_sq * lap_phi - potential_force + source_gravity\n",
        "        return phi_dot, phi_ddot\n",
        "\n",
        "def create_damping_mask_lss(N_grid_dim: int, device: torch.device) -> torch.Tensor:\n",
        "    return torch.ones((N_grid_dim, N_grid_dim, N_grid_dim), dtype=torch.float16, device=device)\n",
        "\n",
        "def update_phi_rk4_lss(phi_current: torch.Tensor, phi_dot_current: torch.Tensor,\n",
        "                       dt: float, model_instance: EFMModule,\n",
        "                       rank: int, device: torch.device) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    with torch.amp.autocast('cuda', enabled=True):\n",
        "        k1_v, k1_a = model_instance.module.nlkg_derivative(phi_current, phi_dot_current)\n",
        "        phi_temp_k2 = phi_current + 0.5 * dt * k1_v\n",
        "        phi_dot_temp_k2 = phi_dot_current + 0.5 * dt * k1_a\n",
        "        k2_v, k2_a = model_instance.module.nlkg_derivative(phi_temp_k2, phi_dot_temp_k2)\n",
        "        phi_temp_k3 = phi_current + 0.5 * dt * k2_v\n",
        "        phi_dot_temp_k3 = phi_dot_current + 0.5 * dt * k2_a\n",
        "        k3_v, k3_a = model_instance.module.nlkg_derivative(phi_temp_k3, phi_dot_temp_k3)\n",
        "        phi_temp_k4 = phi_current + dt * k3_v\n",
        "        phi_dot_temp_k4 = phi_dot_current + dt * k3_a\n",
        "        k4_v, k4_a = model_instance.module.nlkg_derivative(phi_temp_k4, phi_dot_temp_k4)\n",
        "        phi_next = phi_current + (dt / 6.0) * (k1_v + 2*k2_v + 2*k3_v + k4_v)\n",
        "        phi_dot_next = phi_dot_current + (dt / 6.0) * (k1_a + 2*k2_a + 2*k3_a + k4_a)\n",
        "\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize(device)\n",
        "    return phi_next, phi_dot_next\n",
        "\n",
        "def compute_field_energy_lss(phi: torch.Tensor, phi_dot: torch.Tensor,\n",
        "                             m_sq_param: float, g_param: float, eta_param: float,\n",
        "                             dx: float, c_sq_param: float,\n",
        "                             model_instance: EFMModule, rank: int, device: torch.device) -> float:\n",
        "    total_field_energy_val = torch.tensor(0.0, device=device, dtype=torch.float64)\n",
        "    vol_element = dx**3\n",
        "\n",
        "    phi_f32 = phi.to(dtype=torch.float32)\n",
        "    phi_dot_f32 = phi_dot.to(dtype=torch.float32)\n",
        "\n",
        "    with torch.amp.autocast('cuda', enabled=False):\n",
        "        kinetic_density = 0.5 * torch.pow(phi_dot_f32, 2)\n",
        "        potential_density = 0.5 * m_sq_param * torch.pow(phi_f32, 2) + \\\n",
        "                           0.25 * g_param * torch.pow(phi_f32, 4) + \\\n",
        "                           (1.0/6.0) * eta_param * torch.pow(phi_f32, 6)\n",
        "        lap_phi = model_instance.module.conv_laplacian(phi_f32)\n",
        "        gradient_like_density = -0.5 * c_sq_param * (lap_phi * phi_f32)\n",
        "        chunk_field_energy = torch.sum(kinetic_density + potential_density + gradient_like_density) * vol_element\n",
        "\n",
        "    if torch.isnan(chunk_field_energy) or torch.isinf(chunk_field_energy):\n",
        "        return float('nan')\n",
        "\n",
        "    total_field_energy_val = chunk_field_energy.item()\n",
        "    return total_field_energy_val\n",
        "\n",
        "def compute_power_spectrum_lss(phi_cpu_np_array: np.ndarray, k_val_range: list,\n",
        "                               dx_val_param: float, N_grid_param: int) -> tuple[np.ndarray, np.ndarray]:\n",
        "    if not isinstance(phi_cpu_np_array, np.ndarray):\n",
        "        phi_cpu_np_array = phi_cpu_np_array.cpu().numpy()\n",
        "\n",
        "    phi_fft_transform = fftn(phi_cpu_np_array.astype(np.float32))\n",
        "    power_spectrum_raw_data = np.abs(phi_fft_transform)**2 / (N_grid_param**6)\n",
        "    del phi_fft_transform\n",
        "    gc.collect()\n",
        "\n",
        "    kx_coords = fftfreq(N_grid_param, d=dx_val_param) * 2 * np.pi\n",
        "    ky_coords = fftfreq(N_grid_param, d=dx_val_param) * 2 * np.pi\n",
        "    kz_coords = fftfreq(N_grid_param, d=dx_val_param) * 2 * np.pi\n",
        "    kxx_mesh, kyy_mesh, kzz_mesh = np.meshgrid(kx_coords, ky_coords, kz_coords, indexing='ij', sparse=True)\n",
        "    k_magnitude_values = np.sqrt(kxx_mesh**2 + kyy_mesh**2 + kzz_mesh**2)\n",
        "    del kxx_mesh, kyy_mesh, kzz_mesh, kx_coords, ky_coords, kz_coords\n",
        "    gc.collect()\n",
        "\n",
        "    k_bins_def = np.linspace(k_val_range[0], k_val_range[1], 50)\n",
        "    power_binned_values, _, _ = np.histogram(\n",
        "        k_magnitude_values.ravel(), bins=k_bins_def,\n",
        "        weights=power_spectrum_raw_data.ravel(), density=False\n",
        "    )\n",
        "    counts_in_bins, _, _ = np.histogram(k_magnitude_values.ravel(), bins=k_bins_def)\n",
        "    power_binned_final = np.divide(power_binned_values, counts_in_bins,\n",
        "                                   out=np.zeros_like(power_binned_values),\n",
        "                                   where=counts_in_bins!=0)\n",
        "    k_bin_centers_final = (k_bins_def[:-1] + k_bins_def[1:]) / 2\n",
        "\n",
        "    del k_magnitude_values, power_spectrum_raw_data, counts_in_bins\n",
        "    gc.collect()\n",
        "    return k_bin_centers_final, power_binned_final\n",
        "\n",
        "def compute_correlation_function_lss(phi_cpu_np_array: np.ndarray, dx_val_param: float,\n",
        "                                     N_grid_param: int, L_box_param: float) -> tuple[np.ndarray, np.ndarray]:\n",
        "    if not isinstance(phi_cpu_np_array, np.ndarray):\n",
        "        phi_cpu_np_array = phi_cpu_np_array.cpu().numpy()\n",
        "\n",
        "    phi_fft_transform = fftn(phi_cpu_np_array.astype(np.float32))\n",
        "    power_spectrum_raw_data = np.abs(phi_fft_transform)**2\n",
        "    del phi_fft_transform\n",
        "    gc.collect()\n",
        "\n",
        "    correlation_func_raw_data = ifftn(power_spectrum_raw_data).real / (N_grid_param**3)\n",
        "    del power_spectrum_raw_data\n",
        "    gc.collect()\n",
        "\n",
        "    indices_shifted = np.fft.ifftshift(np.arange(N_grid_param)) - (N_grid_param // 2)\n",
        "    rx_coords = indices_shifted * dx_val_param\n",
        "    ry_coords = indices_shifted * dx_val_param\n",
        "    rz_coords = indices_shifted * dx_val_param\n",
        "    rxx_mesh, ryy_mesh, rzz_mesh = np.meshgrid(rx_coords, ry_coords, rz_coords, indexing='ij', sparse=True)\n",
        "    r_magnitude_values = np.sqrt(rxx_mesh**2 + ryy_mesh**2 + rzz_mesh**2)\n",
        "    del rx_coords, ry_coords, rz_coords, rxx_mesh, ryy_mesh, rzz_mesh\n",
        "    gc.collect()\n",
        "\n",
        "    r_bins_def = np.linspace(0, L_box_param / 2, 50)\n",
        "    corr_binned_values, _, _ = np.histogram(\n",
        "        r_magnitude_values.ravel(), bins=r_bins_def,\n",
        "        weights=correlation_func_raw_data.ravel()\n",
        "    )\n",
        "    counts_in_bins, _, _ = np.histogram(r_magnitude_values.ravel(), bins=r_bins_def)\n",
        "    corr_binned_final = np.divide(corr_binned_values, counts_in_bins,\n",
        "                                  out=np.zeros_like(corr_binned_values),\n",
        "                                  where=counts_in_bins!=0)\n",
        "    r_bin_centers_final = (r_bins_def[:-1] + r_bins_def[1:]) / 2\n",
        "\n",
        "    del r_magnitude_values, correlation_func_raw_data, counts_in_bins\n",
        "    gc.collect()\n",
        "    return r_bin_centers_final, corr_binned_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-main-lss-v5-cocalc"
      },
      "source": [
        "## Main Simulation Function (DDP Orchestration)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-main-lss-v5-cocalc"
      },
      "source": [
        "def run_simulation_ddp_orchestrator(rank: int, world_size: int, config_params: dict,\n",
        "                                    checkpoint_dir: str, data_dir: str):\n",
        "    setup_ddp(rank, world_size)\n",
        "    device = torch.device(f'cuda:{rank}')\n",
        "    torch.cuda.set_device(device)\n",
        "\n",
        "    efm_physics_model = EFMModule(\n",
        "        dx=config_params['dx_Mpc'],\n",
        "        m_sq=config_params['m_sim_yr_inv']**2,\n",
        "        g=config_params['g_sim'],\n",
        "        eta=config_params['eta_sim'],\n",
        "        k_gravity=config_params['k_efm_gravity_coupling'],\n",
        "        G_gravity=config_params['G_sim_Mpc_Msolar_yr'],\n",
        "        c_sq=config_params['c_sim_Mpc_yr']**2\n",
        "    ).to(device)\n",
        "    ddp_efm_model = nn.parallel.DistributedDataParallel(efm_physics_model, device_ids=[rank])\n",
        "    ddp_efm_model.eval()\n",
        "\n",
        "    phi = torch.empty((config_params['N'], config_params['N'], config_params['N']), dtype=torch.float16, device=device)\n",
        "    phi_dot = torch.zeros_like(phi, dtype=torch.float16, device=device)\n",
        "    current_start_step = 0\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f'Rank 0: Initializing fields for LSS simulation ({config_params[\"run_id\"]})...')\n",
        "        np.random.seed(42)\n",
        "        initial_phi_np = np.random.randn(config_params['N'], config_params['N'], config_params['N']).astype(np.float16) * config_params['initial_noise_amplitude']\n",
        "        phi = torch.from_numpy(initial_phi_np).to(device, dtype=torch.float16)\n",
        "        phi_dot = torch.zeros_like(phi, dtype=torch.float16, device=device)\n",
        "\n",
        "        checkpoint_file_pattern = os.path.join(checkpoint_dir, f\"intermediate_CKPT_{config_params['run_id']}_step_*.npz\")\n",
        "        list_of_checkpoints = sorted(glob.glob(checkpoint_file_pattern),\n",
        "                                     key=lambda f: int(os.path.basename(f).split('_step_')[1].split('.npz')[0]),\n",
        "                                     reverse=True)\n",
        "        if list_of_checkpoints:\n",
        "            latest_ckpt_path = list_of_checkpoints[0]\n",
        "            print(f'Rank 0: Found latest intermediate LSS checkpoint: {latest_ckpt_path}')\n",
        "            try:\n",
        "                ckpt_data = np.load(latest_ckpt_path, allow_pickle=True)\n",
        "                phi = torch.from_numpy(ckpt_data['phi_r_cpu']).to(device, dtype=torch.float16)\n",
        "                phi_dot = torch.from_numpy(ckpt_data['phi_dot_r_cpu']).to(device, dtype=torch.float16)\n",
        "                current_start_step = ckpt_data['last_step'].item() + 1\n",
        "                print(f'Rank 0: Resuming LSS simulation from step {current_start_step}.')\n",
        "                del ckpt_data\n",
        "                gc.collect()\n",
        "            except Exception as e:\n",
        "                print(f'Rank 0: Error loading intermediate LSS checkpoint: {e}. Starting from scratch.')\n",
        "                current_start_step = 0\n",
        "\n",
        "    try:\n",
        "        dist.broadcast(phi, src=0)\n",
        "        dist.broadcast(phi_dot, src=0)\n",
        "        start_step_tensor = torch.tensor(current_start_step, dtype=torch.int64, device=device)\n",
        "        dist.broadcast(start_step_tensor, src=0)\n",
        "        current_start_step = start_step_tensor.item()\n",
        "    except Exception as e:\n",
        "        print(f'Rank {rank}: Error during DDP broadcast: {e}')\n",
        "        numerical_error_flag = True\n",
        "\n",
        "    dist.barrier()\n",
        "\n",
        "    if rank == 0:\n",
        "        print(f'LSS fields initialized and broadcast to all GPUs. Phi shape: {phi.shape}, Dtype: {phi.dtype}')\n",
        "\n",
        "    num_hist_points = config_params['T_steps'] // config_params['history_every_n_steps'] + 1\n",
        "    field_energy_history = np.zeros(num_hist_points, dtype=np.float64) if rank == 0 else None\n",
        "    density_norm_history = np.zeros(num_hist_points, dtype=np.float64) if rank == 0 else None\n",
        "    current_hist_idx = current_start_step // config_params['history_every_n_steps']\n",
        "\n",
        "    if rank == 0 and current_start_step == 0 and current_hist_idx < num_hist_points:\n",
        "        print(f'Rank 0: Calculating initial observables for LSS simulation...')\n",
        "        field_energy_history[current_hist_idx] = compute_field_energy_lss(\n",
        "            phi, phi_dot, config_params['m_sim_yr_inv']**2, config_params['g_sim'], config_params['eta_sim'],\n",
        "            config_params['dx_Mpc'], config_params['c_sim_Mpc_yr']**2, ddp_efm_model, rank, device\n",
        "        )\n",
        "        density_norm_history[current_hist_idx] = torch.sum(phi.to(torch.float32)**2).item() * config_params['k_efm_gravity_coupling']\n",
        "        print(f'Rank 0 Initial: FE={field_energy_history[current_hist_idx]:.4g}, DN={density_norm_history[current_hist_idx]:.4g}')\n",
        "        current_hist_idx += 1\n",
        "\n",
        "    numerical_error_flag = False\n",
        "    sim_loop_start_time = time.time()\n",
        "\n",
        "    if current_start_step < config_params['T_steps']:\n",
        "        progress_bar = tqdm(range(current_start_step, config_params['T_steps']),\n",
        "                            desc=f'LSS Sim ({config_params[\"run_id\"]}) Rank {rank}',\n",
        "                            initial=current_start_step, total=config_params['T_steps'],\n",
        "                            disable=(rank != 0))\n",
        "\n",
        "        for t_idx in progress_bar:\n",
        "            try:\n",
        "                if torch.any(torch.isinf(phi)) or torch.any(torch.isnan(phi)) or \\\n",
        "                   torch.any(torch.isinf(phi_dot)) or torch.any(torch.isnan(phi_dot)):\n",
        "                    if rank == 0:\n",
        "                        print(f'\\nERROR Rank {rank}: NaN/Inf in fields BEFORE step {t_idx + 1}! Stopping.')\n",
        "                    numerical_error_flag = True\n",
        "                    break\n",
        "\n",
        "                if torch.max(torch.abs(phi)) > 1e5:\n",
        "                    if rank == 0:\n",
        "                        print(f'\\nWARNING Rank {rank}: Excessive field amplitude at step {t_idx + 1}. Max |phi| = {torch.max(torch.abs(phi)):.2e}. Possible instability.')\n",
        "\n",
        "                phi, phi_dot = update_phi_rk4_lss(\n",
        "                    phi, phi_dot, config_params['dt_yr'], ddp_efm_model, rank, device\n",
        "                )\n",
        "\n",
        "                if torch.any(torch.isinf(phi)) or torch.any(torch.isnan(phi)):\n",
        "                    if rank == 0:\n",
        "                        print(f'\\nERROR Rank {rank}: NaN/Inf in phi AFTER step {t_idx + 1}! Stopping.')\n",
        "                    numerical_error_flag = True\n",
        "                    break\n",
        "\n",
        "                if rank == 0 and (t_idx + 1) % 1000 == 0:\n",
        "                    print(f'Rank {rank}: VRAM usage after step {t_idx + 1}:')\n",
        "                    print(f'{device}: {torch.cuda.memory_allocated(device) / 1e9:.2f} GB allocated, {torch.cuda.memory_reserved(device) / 1e9:.2f} GB reserved')\n",
        "\n",
        "                if rank == 0 and (t_idx + 1) % config_params['history_every_n_steps'] == 0:\n",
        "                    if current_hist_idx < num_hist_points:\n",
        "                        current_fe = compute_field_energy_lss(\n",
        "                            phi, phi_dot, config_params['m_sim_yr_inv']**2, config_params['g_sim'], config_params['eta_sim'],\n",
        "                            config_params['dx_Mpc'], config_params['c_sim_Mpc_yr']**2, ddp_efm_model, rank, device\n",
        "                        )\n",
        "                        current_dn = torch.sum(phi.to(torch.float32)**2).item() * config_params['k_efm_gravity_coupling']\n",
        "                        field_energy_history[current_hist_idx] = current_fe\n",
        "                        density_norm_history[current_hist_idx] = current_dn\n",
        "                        progress_bar.set_postfix({'E_field': f'{current_fe:.3e}', 'Norm': f'{current_dn:.3e}'})\n",
        "                        if np.isnan(current_fe) or np.isinf(current_fe):\n",
        "                            print(f'LSS Instability (Rank 0): Energy NaN/Inf at step {t_idx+1}. Stop.')\n",
        "                            numerical_error_flag = True\n",
        "                            break\n",
        "                        current_hist_idx += 1\n",
        "\n",
        "                if rank == 0 and (t_idx + 1) % config_params['checkpoint_every_n_steps'] == 0 and (t_idx + 1) < config_params['T_steps']:\n",
        "                    intermediate_ckpt_file = os.path.join(checkpoint_dir, f\"intermediate_CKPT_{config_params['run_id']}_step_{t_idx+1}.npz\")\n",
        "                    try:\n",
        "                        np.savez_compressed(intermediate_ckpt_file,\n",
        "                                            phi_r_cpu=phi.cpu().numpy(),\n",
        "                                            phi_dot_r_cpu=phi_dot.cpu().numpy(),\n",
        "                                            last_step=t_idx,\n",
        "                                            config_lss_saved=config_params,\n",
        "                                            field_energy_history=field_energy_history[:current_hist_idx],\n",
        "                                            density_norm_history=density_norm_history[:current_hist_idx])\n",
        "                        gc.collect()\n",
        "                        torch.cuda.empty_cache()\n",
        "                    except Exception as e_save:\n",
        "                        print(f'Rank 0: Error saving intermediate LSS checkpoint: {e_save}')\n",
        "\n",
        "                error_tensor = torch.tensor(float(numerical_error_flag), device=device)\n",
        "                dist.all_reduce(error_tensor, op=dist.ReduceOp.MAX)\n",
        "                if error_tensor.item() > 0:\n",
        "                    numerical_error_flag = True\n",
        "                    if rank == 0:\n",
        "                        print(f'Propagated error detected at step {t_idx+1}. Stopping simulation.')\n",
        "                    break\n",
        "\n",
        "            except Exception as e_loop:\n",
        "                if rank == 0:\n",
        "                    print(f'ERROR Rank {rank} in LSS sim loop at step {t_idx + 1}: {e_loop}')\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "                numerical_error_flag = True\n",
        "                break\n",
        "\n",
        "        if rank == 0 and progress_bar is not None:\n",
        "            progress_bar.close()\n",
        "\n",
        "    dist.barrier()\n",
        "    if rank == 0:\n",
        "        sim_duration = time.time() - sim_loop_start_time\n",
        "        print(f'LSS simulation loop finished/resumed in {sim_duration:.2f} s. Numerical Error: {numerical_error_flag}')\n",
        "\n",
        "    if rank == 0:\n",
        "        final_ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        final_ckpt_name = os.path.join(checkpoint_dir, f'FINAL_CKPT_{config_params[\"run_id\"]}_{final_ts}.npz')\n",
        "        try:\n",
        "            if not numerical_error_flag and current_start_step < config_params['T_steps'] and \\\n",
        "               (config_params['T_steps'] % config_params['history_every_n_steps'] != 0 or current_hist_idx == 0) and \\\n",
        "               current_hist_idx < len(field_energy_history):\n",
        "                field_energy_history[current_hist_idx] = compute_field_energy_lss(\n",
        "                    phi, phi_dot, config_params['m_sim_yr_inv']**2, config_params['g_sim'], config_params['eta_sim'],\n",
        "                    config_params['dx_Mpc'], config_params['c_sim_Mpc_yr']**2, ddp_efm_model, rank, device\n",
        "                )\n",
        "                density_norm_history[current_hist_idx] = torch.sum(phi.to(torch.float32)**2).item() * config_params['k_efm_gravity_coupling']\n",
        "                current_hist_idx += 1\n",
        "\n",
        "            np.savez_compressed(final_ckpt_name,\n",
        "                                phi_r_final_cpu=phi.cpu().numpy(),\n",
        "                                phi_dot_r_final_cpu=phi_dot.cpu().numpy(),\n",
        "                                field_energy_history=field_energy_history[:current_hist_idx],\n",
        "                                density_norm_history=density_norm_history[:current_hist_idx],\n",
        "                                config_lss=config_params,\n",
        "                                sim_had_numerical_error=numerical_error_flag)\n",
        "            print(f'Rank 0: LSS final state saved to {final_ckpt_name}')\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "        except Exception as e_final_save:\n",
        "            print(f'Rank 0: Error saving final LSS checkpoint: {e_final_save}')\n",
        "\n",
        "    del phi, phi_dot, ddp_efm_model, efm_physics_model\n",
        "    gc.collect()\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "    cleanup_ddp(rank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "markdown-run-lss-v5-cocalc"
      },
      "source": [
        "## Run Simulation and Analysis Orchestration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "code-run-lss-v5-cocalc"
      },
      "source": [
        "def main_lss_simulation_orchestrator():\n",
        "    world_size_val = torch.cuda.device_count()\n",
        "    if world_size_val < 1:\n",
        "        print('No GPUs available for DDP. This notebook is designed for multi-GPU HPC.')\n",
        "        return\n",
        "\n",
        "    print(f'Starting DDP simulation with {world_size_val} GPUs...')\n",
        "    try:\n",
        "        torch.multiprocessing.set_start_method('spawn', force=True)\n",
        "        for rank in range(world_size_val):\n",
        "            setup_ddp(rank, world_size_val)\n",
        "            run_simulation_ddp_orchestrator(rank, world_size_val, config_lss_run, checkpoint_path_lss_sim, data_path_lss_sim)\n",
        "            cleanup_ddp(rank)\n",
        "    except Exception as e:\n",
        "        print(f'Error in DDP execution: {e}. Falling back to single GPU.')\n",
        "        run_simulation_ddp_orchestrator(0, 1, config_lss_run, checkpoint_path_lss_sim, data_path_lss_sim)\n",
        "\n",
        "    print('\\n--- LSS Final Analysis and Plotting (executed by main process after DDP completion) ---')\n",
        "\n",
        "    plot_config = config_lss_run\n",
        "    hist_fe_plot = np.array([0.0])\n",
        "    hist_dn_plot = np.array([0.0])\n",
        "    phi_final_plot = None\n",
        "    plot_data_loaded = False\n",
        "\n",
        "    final_ckpt_pattern = os.path.join(checkpoint_path_lss_sim, f\"FINAL_CKPT_{config_lss_run['run_id']}_*.npz\")\n",
        "    final_ckpt_files = sorted(glob.glob(final_ckpt_pattern), key=os.path.getmtime, reverse=True)\n",
        "\n",
        "    if not final_ckpt_files:\n",
        "        print(f\"No FINAL LSS checkpoint found for run_id {config_lss_run['run_id']}. Trying latest intermediate...\")\n",
        "        intermediate_ckpt_pattern = os.path.join(checkpoint_path_lss_sim, f\"intermediate_CKPT_{config_lss_run['run_id']}_step_*.npz\")\n",
        "        final_ckpt_files = sorted(glob.glob(intermediate_ckpt_pattern),\n",
        "                                  key=lambda f: int(os.path.basename(f).split('_step_')[1].split('.npz')[0]),\n",
        "                                  reverse=True)\n",
        "        if not final_ckpt_files:\n",
        "            print(f\"No intermediate LSS checkpoint found either for run_id {config_lss_run['run_id']}.\")\n",
        "\n",
        "    if final_ckpt_files:\n",
        "        latest_final_ckpt_path = final_ckpt_files[0]\n",
        "        print(f'Loading LSS data for plotting from: {latest_final_ckpt_path}')\n",
        "        try:\n",
        "            data_for_plot = np.load(latest_final_ckpt_path, allow_pickle=True)\n",
        "            hist_fe_plot = data_for_plot['field_energy_history']\n",
        "            hist_dn_plot = data_for_plot['density_norm_history']\n",
        "\n",
        "            phi_data_key_plot = 'phi_r_final_cpu' if 'phi_r_final_cpu' in data_for_plot else 'phi_r_cpu'\n",
        "            phi_final_plot = data_for_plot[phi_data_key_plot]\n",
        "\n",
        "            config_key_plot = 'config_lss' if 'config_lss' in data_for_plot else 'config_lss_saved'\n",
        "            if config_key_plot in data_for_plot:\n",
        "                plot_config = data_for_plot[config_key_plot].item()\n",
        "            plot_data_loaded = True\n",
        "            print('LSS checkpoint data successfully loaded for plotting.')\n",
        "            if 'sim_had_numerical_error' in data_for_plot and data_for_plot['sim_had_numerical_error']:\n",
        "                print('WARNING: Loaded checkpoint indicates a numerical error occurred during simulation.')\n",
        "        except Exception as e_load_plot:\n",
        "            print(f'Error loading LSS data for plotting: {e_load_plot}')\n",
        "\n",
        "    if plot_data_loaded and len(hist_fe_plot) > 0:\n",
        "        num_hist_points_plot = len(hist_fe_plot)\n",
        "        steps_recorded_plot = np.arange(num_hist_points_plot) * plot_config.get('history_every_n_steps', 100)\n",
        "\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(steps_recorded_plot, hist_fe_plot, marker='.')\n",
        "        plt.title(f'Field Energy Evolution (N={plot_config.get(\"N\")})')\n",
        "        plt.xlabel('Simulation Step')\n",
        "        plt.ylabel('Field Energy (Simulation Units)')\n",
        "        plt.grid(True)\n",
        "        plt.ticklabel_format(style='sci', axis='y', scilimits=(-3,3), useMathText=True)\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(steps_recorded_plot, hist_dn_plot, marker='.')\n",
        "        plt.title(f'Density Norm Evolution (N={plot_config.get(\"N\")})')\n",
        "        plt.xlabel('Simulation Step')\n",
        "        plt.ylabel('kφ² Norm (Simulation Units)')\n",
        "        plt.grid(True)\n",
        "        plt.ticklabel_format(style='sci', axis='y', scilimits=(-3,3), useMathText=True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.suptitle(f'LSS Evolution Metrics ({plot_config.get(\"run_id\", \"N/A\")})', fontsize=14, y=1.02)\n",
        "        plt.savefig(os.path.join(data_path_lss_sim, f'lss_evolution_metrics_{plot_config.get(\"run_id\", \"final_plot\")}.png'))\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        if num_hist_points_plot > 1:\n",
        "            print(f'\\n--- Final LSS Properties from Plot Data ({plot_config.get(\"run_id\")}) ---')\n",
        "            print(f'Final Field Energy: {hist_fe_plot[-1]:.4g}')\n",
        "            print(f'Final Density Norm (kφ²): {hist_dn_plot[-1]:.4g}')\n",
        "            initial_density_norm = plot_config.get('k_efm_gravity_coupling', 0.1) * \\\n",
        "                                   (plot_config.get('initial_noise_amplitude', 0.01)**2 * plot_config.get('N')**3)\n",
        "            if hist_dn_plot[-1] < 1e-7 * initial_density_norm:\n",
        "                print('WARNING: Field appears to have decayed to very low values based on density norm!')\n",
        "\n",
        "        if phi_final_plot is not None and phi_final_plot.ndim == 3 and phi_final_plot.shape[0] > 1 and np.max(np.abs(phi_final_plot)) > 1e-7:\n",
        "            print('\\nComputing P(k) and xi(r) for LSS final state...')\n",
        "            k_min_plot = 2 * np.pi / plot_config['L_Mpc'] * 1.5\n",
        "            k_max_plot = np.pi / plot_config['dx_Mpc'] * 0.5\n",
        "\n",
        "            k_bins_plot, pk_values_plot = compute_power_spectrum_lss(\n",
        "                phi_final_plot, k_val_range=[k_min_plot, k_max_plot],\n",
        "                dx_val_param=plot_config['dx_Mpc'], N_grid_param=plot_config['N']\n",
        "            )\n",
        "            r_bins_plot, xi_values_plot = compute_correlation_function_lss(\n",
        "                phi_final_plot, dx_val_param=plot_config['dx_Mpc'],\n",
        "                N_grid_param=plot_config['N'], L_box_param=plot_config['L_Mpc']\n",
        "            )\n",
        "            del phi_final_plot\n",
        "            gc.collect()\n",
        "\n",
        "            plt.figure(figsize=(16,6))\n",
        "            plt.subplot(1,2,1)\n",
        "            plt.loglog(k_bins_plot, pk_values_plot)\n",
        "            plt.title('LSS Power Spectrum P(k)')\n",
        "            plt.xlabel('k (Mpc$^{-1}$)')\n",
        "            plt.ylabel('P(k) (Mpc$^3$)')\n",
        "            plt.grid(True, which='both', linestyle=':')\n",
        "            plt.axvline(2*np.pi/147, color='r', linestyle='--', label='~147 Mpc (EFM n’=4 BAO-like)')\n",
        "            plt.axvline(2*np.pi/628, color='g', linestyle='--', label='~628 Mpc (EFM n’=1 Primary)')\n",
        "            plt.legend()\n",
        "\n",
        "            plt.subplot(1,2,2)\n",
        "            plt.plot(r_bins_plot, xi_values_plot)\n",
        "            plt.title('LSS Correlation Function $\\xi$(r)')\n",
        "            plt.xlabel('r (Mpc)')\n",
        "            plt.ylabel('$\\xi$(r)')\n",
        "            plt.grid(True, linestyle=':')\n",
        "            plt.axhline(0, color='black', linewidth=0.5)\n",
        "            plt.axvline(147, color='r', linestyle='--', label='~147 Mpc (EFM n’=4 BAO-like)')\n",
        "            plt.axvline(628, color='g', linestyle='--', label='~628 Mpc (EFM n’=1 Primary)')\n",
        "            if len(xi_values_plot[1:]) > 0:\n",
        "                abs_max_xi_plot = np.max(np.abs(xi_values_plot[1:]))\n",
        "                plt.ylim(max(-1.5 * abs_max_xi_plot, np.min(xi_values_plot) - 0.1*abs_max_xi_plot),\n",
        "                         min(1.5 * abs_max_xi_plot, np.max(xi_values_plot) + 0.1*abs_max_xi_plot))\n",
        "            plt.legend()\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.suptitle(f'LSS Observables ({plot_config.get(\"run_id\")})', fontsize=14, y=1.02)\n",
        "            plt.savefig(os.path.join(data_path_lss_sim, f'lss_observables_{plot_config.get(\"run_id\", \"final_plot\")}.png'))\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "            if len(xi_values_plot) > 1 and np.any(np.abs(xi_values_plot[1:]) > 1e-6):\n",
        "                print(f'Correlation peak (max of abs after r=0) near r ~ {r_bins_plot[np.argmax(np.abs(xi_values_plot[1:]))+1]:.1f} Mpc')\n",
        "            else:\n",
        "                print('Correlation function ξ(r) is effectively zero or flat after r=0.')\n",
        "            if len(pk_values_plot) > 0 and np.any(pk_values_plot > 1e-9):\n",
        "                peak_k_idx = np.argmax(pk_values_plot)\n",
        "                print(f'Power spectrum P(k) peak (max value) at k ~ {k_bins_plot[peak_k_idx]:.3f} Mpc^-1 (scale ~ {2*np.pi/k_bins_plot[peak_k_idx]:.1f} Mpc)')\n",
        "            else:\n",
        "                print('Power spectrum P(k) is effectively zero.')\n",
        "        else:\n",
        "            print('Final LSS field data not suitable for P(k)/xi(r) plotting (e.g., decayed to zero or not 3D).')\n",
        "    else:\n",
        "        print('LSS simulation history/final data not available or error occurred during loading. Cannot plot full analysis.')\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print('LSS plotting and analysis main function finished.')\n",
        "\n",
        "main_lss_simulation_orchestrator()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0
}
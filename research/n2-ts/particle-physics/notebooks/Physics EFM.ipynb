{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EFM Paper 2 Simulation: Eholokon Dynamics\n",
        "\n",
        "This notebook simulates eholokon dynamics for the paper 'The Ehokolo Fluxon Model: A Foundation for Physics from Eholokon Dynamics.' We model a scalar field \\(\\phi\\) with EM coupling on a 200³ grid (2 nm, atomic scales) to derive particle properties (mass, spin, charge) and validate electromagnetic interactions in the S=T state. Weak, strong, and gravity forces are approximated via relaxation, clustering, and density gradients. A 1000³ grid is used for cosmological validation where appropriate, ensuring efficient resource use on Google Colab Pro+.\n",
        "\n",
        "## Objectives\n",
        "- Simulate a 200³ grid for EM dynamics and particle properties in S=T.\n",
        "- Approximate weak (relaxation), strong (clustering), and gravity (density) forces.\n",
        "- Validate against NIST atomic spectra (hydrogen emission lines).\n",
        "- Test a 1000³ grid for cosmological scales, optimizing memory usage.\n",
        "- Provide transparent code for peer validation.\n",
        "\n",
        "## Hardware\n",
        "- **GPU**: NVIDIA A100 (40GB VRAM)\n",
        "- **System RAM**: ~80GB\n",
        "- **Environment**: Google Colab Pro+\n",
        "\n",
        "## Setup Instructions\n",
        "1. Go to `Runtime` > `Change runtime type` > Select `A100 GPU`.\n",
        "2. Run `!nvidia-smi` to verify GPU.\n",
        "3. Execute all cells sequentially."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clear GPU memory\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# Install dependencies\n",
        "!pip install --quiet torch numpy matplotlib tqdm psutil scipy scikit-learn\n",
        "!nvidia-smi\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import psutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "from IPython.display import Image, display\n",
        "from scipy.fft import fftn, fftfreq\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.cluster import DBSCAN\n",
        "import os\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if device.type == 'cuda':\n",
        "    try:\n",
        "        print(f'GPU VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
        "    except:\n",
        "        print('Error: No GPU detected.')\n",
        "print(f'System RAM Total: {psutil.virtual_memory().total / 1e9:.2f} GB')\n",
        "print(f'System RAM Available: {psutil.virtual_memory().available / 1e9:.2f} GB')\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(f'Error mounting Google Drive: {e}')\n",
        "    raise\n",
        "\n",
        "# Define directories\n",
        "checkpoint_path = '/content/drive/MyDrive/EFM_checkpoints_paper2/'\n",
        "data_path = '/content/drive/MyDrive/EFM_data_paper2/'\n",
        "for path in [checkpoint_path, data_path]:\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "    except Exception as e:\n",
        "        print(f'Error creating directory {path}: {e}')\n",
        "        raise\n",
        "\n",
        "# NIST atomic spectra (hydrogen lines, wavelengths in meters)\n",
        "nist_spectra = {'H_alpha': 656.3e-9, 'H_beta': 486.1e-9, 'H_gamma': 434.0e-9}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulation Setup\n",
        "\n",
        "- **Grid Size**: 200³ (atomic, 2 nm); 1000³ (cosmological, 10 Mpc, where appropriate)\n",
        "- **Box Size**: 2e-9 m (atomic); 10 Mpc (cosmological)\n",
        "- **Time Step**: 1e-15 s (atomic); 0.0005 units (cosmological, TBD)\n",
        "- **Steps**: 5000 (atomic); 10000 (cosmological)\n",
        "- **Initial Conditions**: Gaussian pulse (\\(\\phi = 0.3 e^{-R^2 / (2 \\sigma^2)}\\), \\(\\sigma=0.1 \\, \\text{nm}\\)) for S/T (atomic); two sech profiles for S/T (cosmological). T/S as gradient of S/T, S=T as \\(\\phi - \\phi_{\\text{TS}}\\). Maps to \\(n'=1\\) (S=T, resonant).\n",
        "- **Boundary Conditions**: Absorbing (damping factor=0.05, width=5% of grid)\n",
        "- **Parameters**: \\(m=0.0005\\), \\(g=3.3\\), \\(\\eta=0.012\\), \\(q=0.01\\), \\(\\delta=0.06\\), \\(\\gamma=0.0225\\), \\(k=0.01\\) (derived via stability analysis to match NIST spectra).\n",
        "- **Notes**: Atomic simulations validate EM dynamics; cosmological tests use a simplified NLKG for clustering and \\(H_0\\).\n",
        "\n",
        "The simulation models \\(\\phi\\) with EM coupling for particle properties and Maxwell’s equations, approximating other forces via field dynamics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parameters\n",
        "grid_size = 200  # Set to 1000 for cosmological runs\n",
        "L = 2e-9  # 2 nm (atomic); 10e6 for cosmological (10 Mpc)\n",
        "dx = L / grid_size\n",
        "dt = 1e-15  # 0.0005 for cosmological\n",
        "T = 5000   # 10000 for cosmological\n",
        "m = 0.0005  # Derived via stability analysis\n",
        "g = 3.3     # Nonlinear coupling for optical resonance\n",
        "eta = 0.012 # Singularity prevention\n",
        "q = 0.01    # EM coupling strength\n",
        "delta = 0.06\n",
        "gamma = 0.0225\n",
        "c = 3e8\n",
        "k = 0.01  # Calibrated to electron mass (TBD)\n",
        "\n",
        "# Initialize complex field\n",
        "torch.set_default_dtype(torch.complex64)\n",
        "x = torch.linspace(-L/2, L/2, grid_size, device=device, dtype=torch.float32)\n",
        "X, Y, Z = torch.meshgrid(x, x, x, indexing='ij')\n",
        "R = torch.sqrt(X**2 + Y**2 + Z**2)\n",
        "sigma = 1e-10  # 1.0 for cosmological\n",
        "phi = 0.3 * torch.exp(-R**2 / (2 * sigma**2)) * torch.ones((grid_size, grid_size, grid_size), device=device, dtype=torch.complex64)\n",
        "phi_dot = torch.zeros_like(phi, dtype=torch.complex64)\n",
        "A_mu = torch.zeros_like(phi, dtype=torch.float32)  # Scalar potential\n",
        "del X, Y, Z, R\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Potential\n",
        "def potential(phi):\n",
        "    phi_abs_sq = torch.abs(phi)**2\n",
        "    return (m**2 / 2) * phi_abs_sq + (g / 4) * phi_abs_sq**2 + (eta / 6) * phi_abs_sq**3\n",
        "\n",
        "# NLKG derivative\n",
        "def nlkg_derivative(phi, phi_dot, A_mu):\n",
        "    with torch.no_grad():\n",
        "        # Optimized Laplacian\n",
        "        kernel = torch.tensor([[[0, 0, 0], [0, 1, 0], [0, 0, 0]],\n",
        "                               [[0, 1, 0], [1, -6, 1], [0, 1, 0]],\n",
        "                               [[0, 0, 0], [0, 1, 0], [0, 0, 0]]], dtype=torch.float32, device=device)\n",
        "        kernel = kernel / dx**2\n",
        "        laplacian = torch.nn.functional.conv3d(phi.unsqueeze(0).unsqueeze(0).real, kernel.unsqueeze(0).unsqueeze(0), padding=1).squeeze()\n",
        "\n",
        "        # Absorbing boundaries\n",
        "        boundary_width = int(0.05 * grid_size)\n",
        "        damping_factor = 0.05\n",
        "        mask = torch.ones_like(phi, dtype=torch.float32)\n",
        "        for dim in range(3):\n",
        "            indices = torch.arange(grid_size, device=device)\n",
        "            damping = torch.ones(grid_size, device=device, dtype=torch.float32)\n",
        "            damping[:boundary_width] = damping_factor + (1 - damping_factor) * indices[:boundary_width] / boundary_width\n",
        "            damping[-boundary_width:] = damping_factor + (1 - damping_factor) * (grid_size - 1 - indices[-boundary_width:]) / boundary_width\n",
        "            if dim == 0:\n",
        "                mask = damping[:, None, None] * mask\n",
        "            elif dim == 1:\n",
        "                mask = damping[None, :, None] * mask\n",
        "            else:\n",
        "                mask = damping[None, None, :] * mask\n",
        "        phi_damped = phi * mask\n",
        "        phi_dot_damped = phi_dot * mask\n",
        "\n",
        "        # Covariant derivative\n",
        "        D_t_phi = phi_dot - 1j * q * A_mu * phi\n",
        "        grad_phi = torch.stack(torch.gradient(phi_damped.real, spacing=dx, dim=[0, 1, 2]))\n",
        "        D2_phi = c**2 * laplacian - 1j * q * torch.stack(torch.gradient(A_mu, spacing=dx, dim=[0, 1, 2]))\n",
        "\n",
        "        # NLKG terms\n",
        "        phi_abs_sq = torch.abs(phi_damped)**2\n",
        "        dV_dphi = (m**2 * phi_damped + g * phi_abs_sq * phi_damped + eta * phi_abs_sq**2 * phi_damped)\n",
        "        dissipation = delta * (torch.abs(D_t_phi)**2) * phi_damped\n",
        "        reciprocity = gamma * phi_damped\n",
        "        phi_ddot = -D2_phi - dV_dphi - dissipation + reciprocity\n",
        "\n",
        "        # Maxwell's equation (simplified)\n",
        "        J_mu = 1j * q * (torch.conj(phi_damped) * D_t_phi - phi_damped * torch.conj(D_t_phi))\n",
        "        lap_A = torch.nn.functional.conv3d(A_mu.unsqueeze(0).unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0), padding=1).squeeze()\n",
        "        A_mu_new = lap_A + torch.real(J_mu)\n",
        "\n",
        "        return phi_dot_damped, phi_ddot, A_mu_new\n",
        "\n",
        "# RK4 integrator\n",
        "def update_phi(phi, phi_dot, A_mu, dt):\n",
        "    with torch.no_grad():\n",
        "        k1_v, k1_a, k1_A = nlkg_derivative(phi, phi_dot, A_mu)\n",
        "        k2_v, k2_a, k2_A = nlkg_derivative(phi + 0.5 * dt * k1_v, phi_dot + 0.5 * dt * k1_a, A_mu + 0.5 * dt * k1_A)\n",
        "        k3_v, k3_a, k3_A = nlkg_derivative(phi + 0.5 * dt * k2_v, phi_dot + 0.5 * dt * k2_a, A_mu + 0.5 * dt * k2_A)\n",
        "        k4_v, k4_a, k4_A = nlkg_derivative(phi + dt * k3_v, phi_dot + dt * k3_a, A_mu + dt * k3_A)\n",
        "        phi_new = phi + (dt / 6.0) * (k1_v + 2 * k2_v + 2 * k3_v + k4_v)\n",
        "        phi_dot_new = phi_dot + (dt / 6.0) * (k1_a + 2 * k2_a + 2 * k3_a + k4_a)\n",
        "        A_mu_new = A_mu + (dt / 6.0) * (k1_A + 2 * k2_A + 2 * k3_A + k4_A)\n",
        "        del k1_v, k1_a, k1_A, k2_v, k2_a, k2_A, k3_v, k3_a, k3_A, k4_v, k4_a, k4_A\n",
        "        torch.cuda.empty_cache()\n",
        "        return phi_new, phi_dot_new, A_mu_new\n",
        "\n",
        "# Energy calculation\n",
        "def compute_energy(phi, phi_dot):\n",
        "    with torch.no_grad():\n",
        "        grad_phi = torch.stack(torch.gradient(phi.real, spacing=dx, dim=[0, 1, 2]))\n",
        "        kinetic = 0.5 * torch.abs(phi_dot)**2\n",
        "        gradient = 0.5 * torch.sum(grad_phi**2, dim=0)\n",
        "        potential_energy = potential(phi)\n",
        "        total = torch.sum(kinetic + gradient + potential_energy) * dx**3\n",
        "        return total.item(), torch.sum(kinetic).item() * dx**3, torch.sum(gradient).item() * dx**3, torch.sum(potential_energy).item() * dx**3\n",
        "\n",
        "# Mass\n",
        "def compute_mass(phi, dx, k=0.01):\n",
        "    return k * torch.sum(torch.abs(phi)**2) * dx**3\n",
        "\n",
        "# Spin\n",
        "def compute_spin(phi, dx):\n",
        "    grad_phi = torch.stack(torch.gradient(phi.real, spacing=dx, dim=[0, 1, 2]))\n",
        "    curl = grad_phi[1] * grad_phi[2] - grad_phi[2] * grad_phi[1]  # x-component\n",
        "    return torch.sum(torch.abs(curl)).item() * dx**3\n",
        "\n",
        "# Charge\n",
        "def compute_charge(phi, phi_dot, A_mu, dx, q=0.01):\n",
        "    D_t_phi = phi_dot - 1j * q * A_mu * phi\n",
        "    J_mu = 1j * q * (torch.conj(phi) * D_t_phi - phi * torch.conj(D_t_phi))\n",
        "    return torch.sum(torch.real(J_mu)).item() * dx**3\n",
        "\n",
        "# Frequency spectrum\n",
        "def compute_frequency_spectrum(phi, dt, N_t):\n",
        "    phi_center = phi[grid_size//2, grid_size//2, grid_size//2].cpu().numpy()\n",
        "    fft_result = np.fft.fft(phi_center)\n",
        "    freqs = np.fft.fftfreq(N_t, dt)\n",
        "    return freqs[:N_t//2], np.abs(fft_result)[:N_t//2]\n",
        "\n",
        "# Weak force relaxation\n",
        "def compute_relaxation(energy_history):\n",
        "    if len(energy_history) < 10:\n",
        "        return 0\n",
        "    t = np.arange(len(energy_history))\n",
        "    def exp_decay(t, A, tau):\n",
        "        return A * np.exp(-t / tau)\n",
        "    popt, _ = curve_fit(exp_decay, t, energy_history, p0=[energy_history[0], 1000])\n",
        "    return popt[1]  # Decay time\n",
        "\n",
        "# Strong force binding (DBSCAN)\n",
        "def compute_binding(phi, threshold=0.5):\n",
        "    rho = torch.abs(phi)**2\n",
        "    coords = np.where(rho.cpu().numpy() > threshold)\n",
        "    if len(coords[0]) < 2:\n",
        "        return 0\n",
        "    points = np.vstack(coords).T\n",
        "    db = DBSCAN(eps=dx*2, min_samples=5).fit(points)\n",
        "    return len(np.unique(db.labels_)) - (1 if -1 in db.labels_ else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter Derivation\n",
        "\n",
        "Parameters (\\(m=0.0005\\), \\(g=3.3\\), \\(\\eta=0.012\\), \\(q=0.01\\), \\(\\delta=0.06\\), \\(\\gamma=0.0225\\), \\(k=0.01\\)) are derived via stability analysis of the NLKG equation for \\(n'=1\\) (S=T, resonant state). We solve for steady-state \\(\\phi_{n'} = \\sqrt{\\rho_{n'} / k}\\), with \\(\\rho_{n'} = \\rho_{\\text{ref}} / n'\\), \\(\\rho_{\\text{ref}} = 1.5\\), \\(k=0.01\\), ensuring frequency peaks at ~5×10¹⁴ Hz (NIST hydrogen lines). The analysis is preliminary and will be refined in future runs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulation Loop\n",
        "\n",
        "The loop updates \\(\\phi\\) and \\(A_\\mu\\), tracks energy, and computes particle properties (mass, spin, charge) and force analogues (weak: relaxation, strong: clustering, gravity: density). Results are validated against NIST spectra. A 1000³ grid is used for cosmological tests with adjusted parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "energy_history = []\n",
        "mass_history = []\n",
        "spin_history = []\n",
        "charge_history = []\n",
        "binding_history = []\n",
        "phi_center_time = []\n",
        "start_time = time.time()\n",
        "\n",
        "pbar = tqdm(range(T), desc='Simulation Progress')\n",
        "for t in pbar:\n",
        "    phi, phi_dot, A_mu = update_phi(phi, phi_dot, A_mu, dt)\n",
        "    grad_ST = torch.stack(torch.gradient(phi.real, spacing=dx, dim=[0, 1, 2]))\n",
        "    phi_TS = -torch.sqrt(grad_ST[0]**2 + grad_ST[1]**2 + grad_ST[2]**2).to(dtype=torch.complex64)\n",
        "    phi_S_eq_T = phi - phi_TS\n",
        "\n",
        "    total_energy, kinetic, gradient, pot_energy = compute_energy(phi, phi_dot)\n",
        "    energy_history.append(total_energy)\n",
        "    mass_history.append(compute_mass(phi, dx).item())\n",
        "    spin_history.append(compute_spin(phi.real, dx))\n",
        "    charge_history.append(compute_charge(phi, phi_dot, A_mu, dx))\n",
        "    binding_history.append(compute_binding(phi))\n",
        "    phi_center_time.append(phi[grid_size//2, grid_size//2, grid_size//2].item())\n",
        "\n",
        "    # NIST validation\n",
        "    if t % 1000 == 0 or t == T - 1:\n",
        "        freqs, fft_magnitude = compute_frequency_spectrum(torch.tensor(phi_center_time), dt, T)\n",
        "        peak_freq = freqs[np.argmax(fft_magnitude)]\n",
        "        peak_wavelength = c / peak_freq\n",
        "        print(f'Step {t}: Peak frequency {peak_freq:.2e} Hz, Wavelength {peak_wavelength:.2e} m')\n",
        "        for line, wavelength in nist_spectra.items():\n",
        "            error = abs(peak_wavelength - wavelength) / wavelength * 100\n",
        "            print(f'  {line}: NIST {wavelength:.2e} m, Error {error:.2f}%')\n",
        "\n",
        "    # Save and visualize\n",
        "    if t % 1000 == 0 or t == T - 1:\n",
        "        try:\n",
        "            torch.save({'step': t, 'phi': phi, 'phi_dot': phi_dot, 'A_mu': A_mu},\n",
        "                       f'{checkpoint_path}checkpoint_{t}.pt')\n",
        "            print(f'Checkpoint saved at step {t}')\n",
        "        except Exception as e:\n",
        "            print(f'Error saving checkpoint: {e}')\n",
        "\n",
        "        phi_ST_np = phi.cpu().numpy().real\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        ax = plt.axes(projection='3d')\n",
        "        x = np.linspace(-L/2, L/2, grid_size)\n",
        "        X, Y, Z = np.meshgrid(x, x, x)\n",
        "        mask = phi_ST_np > 0.1\n",
        "        ax.scatter(X[mask], Y[mask], Z[mask], c=phi_ST_np[mask], cmap='viridis', s=1)\n",
        "        ax.set_title(f'S/T Field at Step {t}')\n",
        "        plt.savefig(f'{data_path}fields_step_{t}.png')\n",
        "        plt.close()\n",
        "\n",
        "    vram_used = torch.cuda.memory_allocated() / 1e9 if device.type == 'cuda' else 0\n",
        "    ram_used = psutil.virtual_memory().used / 1e9\n",
        "    if t % 100 == 0:\n",
        "        pbar.set_postfix({'VRAM': f'{vram_used:.2f}GB', 'RAM': f'{ram_used:.2f}GB'})\n",
        "    if vram_used > 32 or ram_used > 64:\n",
        "        print(f'Warning: Resource usage high at step {t}')\n",
        "        break\n",
        "\n",
        "print(f'Simulation completed in {time.time() - start_time:.2f} seconds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis and Visualization\n",
        "\n",
        "Analyze energy conservation, particle properties (mass, spin, charge), frequency spectrum (NIST validation), and force analogues (weak: decay time, strong: clusters, gravity: density gradients). Results are saved for peer validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "energy_history_clean = [e for e in energy_history if np.isfinite(e)]\n",
        "plt.semilogy(energy_history_clean, label='Total Energy')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Energy (log scale)')\n",
        "plt.title('Energy Conservation')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.savefig(f'{data_path}energy_total.png')\n",
        "plt.close()\n",
        "display(Image(filename=f'{data_path}energy_total.png'))\n",
        "\n",
        "# Particle properties\n",
        "print(f'Final Mass: {mass_history[-1]:.4e} (calibrated TBD)')\n",
        "print(f'Final Spin: {spin_history[-1]:.4e} (calibrated TBD)')\n",
        "print(f'Final Charge: {charge_history[-1]:.4e} (calibrated TBD)')\n",
        "print(f'Final Binding: {binding_history[-1]} clusters')\n",
        "\n",
        "# NIST validation\n",
        "freqs, fft_magnitude = compute_frequency_spectrum(torch.tensor(phi_center_time), dt, T)\n",
        "peak_freq = freqs[np.argmax(fft_magnitude)]\n",
        "peak_wavelength = c / peak_freq\n",
        "print(f'Final Peak Frequency: {peak_freq:.2e} Hz, Wavelength: {peak_wavelength:.2e} m')\n",
        "for line, wavelength in nist_spectra.items():\n",
        "    error = abs(peak_wavelength - wavelength) / wavelength * 100\n",
        "    print(f'{line}: NIST {wavelength:.2e} m, Error {error:.2f}%')\n",
        "\n",
        "# Weak force decay\n",
        "t = np.arange(len(energy_history_clean))\n",
        "def exp_decay(t, A, tau):\n",
        "    return A * np.exp(-t / tau)\n",
        "popt, _ = curve_fit(exp_decay, t, energy_history_clean, p0=[energy_history_clean[0], 1000])\n",
        "print(f'Weak Force Decay Time: {popt[1]:.2f} steps')\n",
        "\n",
        "# Save data\n",
        "try:\n",
        "    np.save(f'{data_path}mass_history.npy', np.array(mass_history))\n",
        "    np.save(f'{data_path}spin_history.npy', np.array(spin_history))\n",
        "    np.save(f'{data_path}charge_history.npy', np.array(charge_history))\n",
        "    np.save(f'{data_path}binding_history.npy', np.array(binding_history))\n",
        "    np.save(f'{data_path}frequency_spectrum_freqs.npy', freqs)\n",
        "    np.save(f'{data_path}frequency_spectrum_values.npy', fft_magnitude)\n",
        "except Exception as e:\n",
        "    print(f'Error saving data: {e}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}